{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在windows中安装caffe\n",
    "关于caffe，不用多说，搞深度学习的都知道。本文结合自己的电脑，记录下windows下caffe的安装过程，以供备忘。  \n",
    "## 1.编译前的准备工作\n",
    "在https://github.com/Microsoft/caffe 将项目clone下来，保存在本地，根目录我们后文称之为CAFFE_ROOT。CAFFE_ROOT内有一个和官方Caffe很不同的地方，多了一个windows文件夹。打开文件夹就是微软已经为我们建立好的vs工程，在开始之前需要先将CAFFE_ROOT\\windows\\CommonSettings.props.example 文件复制一份，并命名为CommonSettings.props 这里保存着编译的一些设置内容。打开CAFFE_ROOT\\windows\\CommonSettings.props 里面有几点重要的设置需要注意 \n",
    "```\n",
    "    <CpuOnlyBuild>false</CpuOnlyBuild>\n",
    "    <UseCuDNN>true</UseCuDNN>\n",
    "    <CudaVersion>7.5</CudaVersion>\n",
    "    <PythonSupport>true</PythonSupport>\n",
    "    <MatlabSupport>false</MatlabSupport>\n",
    "```\n",
    "第一个设置为false表示只使用GPU；第二个选择true表示使用CuDNN，反之为false；第三项为CUDA的版本，使用GPU需要安装CUDA，可以在NVIDIA官网下载[7.5版本的CUDA](https://developer.nvidia.com/cuda-downloads)进行安装；第四项、第五项分别表示是否安装python、matlab支持，这里我选择了安装python支持。  \n",
    "### 安装cudnn  \n",
    "在nvdia官网下载对应版本的[cudnn](https://developer.nvidia.com/rdp/cudnn-download)。下载后解压，有三个目录：`bin`、`include`、`lib`。将这三个目录下的文件拷贝到CUDA_HOME对应的目录中，以笔者电脑为例，路径分别是：\n",
    "* `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v7.5\\bin`\n",
    "* `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v7.5\\include`\n",
    "* `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v7.5\\lib\\x64`\n",
    "\n",
    "其实不一定要这三个目录， 但必须是加入PATH的路径。  \n",
    "用 vs 新建 cuda 项目。在vs编辑器正上方，Solution Configuration 的内容如果是Debug ,改为 Release ,旁边Platforms Solution Platforms 中的内容如果是win32，要改选为x64。\n",
    "\n",
    "接下来修改项目属性:\n",
    "\n",
    "项目属性/VC++ Directories/Include Directories 中添加入include的路径(例如 d:\\cuda\\include);\n",
    "\n",
    "在项目属性/VC++ Directories/Libary Directories 中添加入lib\\x64路径(例如 d:\\cuda\\lib\\x64);\n",
    "\n",
    "在项目属性/Linker/Input/Additional Dependencies  中添加入cudnn.lib;\n",
    "\n",
    "项目属性/CUDA C|C++ / Device /Code Generation 中，将sm_20改为 sm_30或更高;\n",
    "\n",
    "项目属性修改完毕。\n",
    "\n",
    "\n",
    "加入如下代码：\n",
    "```C\n",
    "#include <iostream>\n",
    "#include <cuda_runtime.h>\n",
    "#include <cudnn.h>\n",
    "using namespace std;\n",
    "\n",
    "void main(){\n",
    "    cudnnHandle_t handle;\n",
    "    cudnnStatus_t t = cudnnCreate(&handle);\n",
    "    cout<< cudnnGetErrorString(t);\n",
    "    getchar();\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "如果结果显示:\n",
    "\n",
    "`CUDNN_STATES_SUCCESS`\n",
    "\n",
    "表明安装成功了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置python接口\n",
    "\n",
    "如果要调用caffe的python接口，需要修改`CommonSettings.props`中的`PythonDir`属性。在文件中找到如下段落：\n",
    "```xml\n",
    "    <PropertyGroup Condition=\"'$(PythonSupport)'=='true'\">\n",
    "        <PythonDir>C:\\Miniconda2\\</PythonDir>\n",
    "        <LibraryPath>$(PythonDir)\\libs;$(LibraryPath)</LibraryPath>\n",
    "        <IncludePath>$(PythonDir)\\include;$(IncludePath)</IncludePath>\n",
    "    </PropertyGroup>\n",
    "```\n",
    "`PythonDir`属性的默认值是Miniconda2，可以根据需要改成你安装python的根目录，笔者安装python的根目录是`C:\\Anaconda2`。因此将配置改为\n",
    "\n",
    "```xml\n",
    "    <PropertyGroup Condition=\"'$(PythonSupport)'=='true'\">\n",
    "        <PythonDir>C:\\Anaconda2\\</PythonDir>\n",
    "        <LibraryPath>$(PythonDir)\\libs;$(LibraryPath)</LibraryPath>\n",
    "        <IncludePath>$(PythonDir)\\include;$(IncludePath)</IncludePath>\n",
    "    </PropertyGroup>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.编译libcaffe、caffe和pycaffe\n",
    "打开 CAFFE_ROOT\\windows\\Caffe.sln 对libcaffe、caffe和pycaffe项目做如下设置  \n",
    "`项目→属性→C/C++→常规→将警告视为错误 设置为否`\n",
    "如果不设置的话在编译boost库的时候会由于文字编码的警告而报错  \n",
    "选择编译环境为Release，x64（其他环境同理）。首先编译libcaffe，在libcaffe上右键生成就可以了。  \n",
    "接着编译caffe和pycaffe，过程与前者类似。所有编译成功和运行需要的dll文件都会存储在`CAFFE_ROOT\\Build\\x64\\Release`下。至此，Windows版的Caffe编译就成功了。  \n",
    "最后，需要进行pycaffe的相关配置，将`CAFFE_ROOT\\Build\\x64\\Release\\pycaffe`加入环境变量`PythonPath`或者将`CAFFE_ROOT\\Build\\x64\\Release\\pycaffe\\caffe`拷贝到`<python_root>\\Lib\\site-packages`下（`<python_root>`为python的安装目录，笔者安装python的根目录是C:\\Anaconda2）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.在python中调用caffe\n",
    "在导入caffe之前，要事先安装protobuf，安装命令为  \n",
    "```\n",
    "pip install protobuf\n",
    "```  \n",
    "否则将会报如下错误：\n",
    "```\n",
    "ImportError: No module named google.protobuf.internal\n",
    "```\n",
    "接着在python中导入caffe\n",
    "```\n",
    "import caffe\n",
    "```\n",
    "不出意外的话导入应该是成功的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.mnist手写数字分类\n",
    "接下来用一个mnist手写数字分类的程序来测试一下安装过程是否完整无误，代码来自博客http://www.cnblogs.com/denny402/p/5684431.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import caffe\n",
    "from caffe import layers as L, params as P, proto, to_proto\n",
    "\n",
    "# 设定文件的保存路径\n",
    "root = 'G:/workspace/caffe/'  # 根目录\n",
    "train_list = root + 'mnist/train/train.txt'  # 训练图片列表\n",
    "test_list = root + 'mnist/test/test.txt'  # 测试图片列表\n",
    "train_proto = root + 'mnist/train.prototxt'  # 训练配置文件\n",
    "test_proto = root + 'mnist/test.prototxt'  # 测试配置文件\n",
    "solver_proto = root + 'mnist/solver.prototxt'  # 参数文件\n",
    "\n",
    "\n",
    "# 编写一个函数，生成配置文件prototxt\n",
    "def Lenet(img_list, batch_size, include_acc=False):\n",
    "    # 第一层，数据输入层，以ImageData格式输入\n",
    "    data, label = L.ImageData(source=img_list, batch_size=batch_size, ntop=2, root_folder=root,\n",
    "                              transform_param=dict(scale=0.00390625))\n",
    "    # 第二层：卷积层\n",
    "    conv1 = L.Convolution(data, kernel_size=5, stride=1, num_output=20, pad=0, weight_filler=dict(type='xavier'))\n",
    "    # 池化层\n",
    "    pool1 = L.Pooling(conv1, pool=P.Pooling.MAX, kernel_size=2, stride=2)\n",
    "    # 卷积层\n",
    "    conv2 = L.Convolution(pool1, kernel_size=5, stride=1, num_output=50, pad=0, weight_filler=dict(type='xavier'))\n",
    "    # 池化层\n",
    "    pool2 = L.Pooling(conv2, pool=P.Pooling.MAX, kernel_size=2, stride=2)\n",
    "    # 全连接层\n",
    "    fc3 = L.InnerProduct(pool2, num_output=500, weight_filler=dict(type='xavier'))\n",
    "    # 激活函数层\n",
    "    relu3 = L.ReLU(fc3, in_place=True)\n",
    "    # 全连接层\n",
    "    fc4 = L.InnerProduct(relu3, num_output=10, weight_filler=dict(type='xavier'))\n",
    "    # softmax层\n",
    "    loss = L.SoftmaxWithLoss(fc4, label)\n",
    "\n",
    "    if include_acc:  # test阶段需要有accuracy层\n",
    "        acc = L.Accuracy(fc4, label)\n",
    "        return to_proto(loss, acc)\n",
    "    else:\n",
    "        return to_proto(loss)\n",
    "\n",
    "\n",
    "def write_net():\n",
    "    # 写入train.prototxt\n",
    "    with open(train_proto, 'w') as f:\n",
    "        f.write(str(Lenet(train_list, batch_size=64)))\n",
    "\n",
    "    # 写入test.prototxt\n",
    "    with open(test_proto, 'w') as f:\n",
    "        f.write(str(Lenet(test_list, batch_size=100, include_acc=True)))\n",
    "\n",
    "\n",
    "# 编写一个函数，生成参数文件\n",
    "def gen_solver(solver_file, train_net, test_net):\n",
    "    s = proto.caffe_pb2.SolverParameter()\n",
    "    s.train_net = train_net\n",
    "    s.test_net.append(test_net)\n",
    "    s.test_interval = 938  # 60000/64，测试间隔参数：训练完一次所有的图片，进行一次测试\n",
    "    s.test_iter.append(500)  # 50000/100 测试迭代次数，需要迭代500次，才完成一次所有数据的测试\n",
    "    s.max_iter = 9380  # 10 epochs , 938*10，最大训练次数\n",
    "    s.base_lr = 0.01  # 基础学习率\n",
    "    s.momentum = 0.9  # 动量\n",
    "    s.weight_decay = 5e-4  # 权值衰减项\n",
    "    s.lr_policy = 'step'  # 学习率变化规则\n",
    "    s.stepsize = 3000  # 学习率变化频率\n",
    "    s.gamma = 0.1  # 学习率变化指数\n",
    "    s.display = 20  # 屏幕显示间隔\n",
    "    s.snapshot = 938  # 保存caffemodel的间隔\n",
    "    s.snapshot_prefix = root + 'mnist/lenet'  # caffemodel前缀\n",
    "    s.type = 'SGD'  # 优化算法\n",
    "    s.solver_mode = proto.caffe_pb2.SolverParameter.GPU  # 加速\n",
    "    # 写入solver.prototxt\n",
    "    with open(solver_file, 'w') as f:\n",
    "        f.write(str(s))\n",
    "\n",
    "\n",
    "# 开始训练\n",
    "def training(solver_proto):\n",
    "    caffe.set_device(0)\n",
    "    caffe.set_mode_gpu()\n",
    "    solver = caffe.SGDSolver(solver_proto)\n",
    "    solver.solve()\n",
    "\n",
    "\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    write_net()\n",
    "    gen_solver(solver_proto, train_proto, test_proto)\n",
    "    training(solver_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行日志"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "C:\\Anaconda2\\python.exe \"D:/Documents/Python Scripts/Machine-Learning-Notes/caffe/mnist.py\"\n",
    "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
    "I0930 23:31:05.395361 14384 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.\n",
    "I0930 23:31:05.398365 14384 solver.cpp:48] Initializing solver from parameters: \n",
    "train_net: \"G:/workspace/caffe/mnist/train.prototxt\"\n",
    "test_net: \"G:/workspace/caffe/mnist/test.prototxt\"\n",
    "test_iter: 500\n",
    "test_interval: 938\n",
    "base_lr: 0.01\n",
    "display: 20\n",
    "max_iter: 9380\n",
    "lr_policy: \"step\"\n",
    "gamma: 0.1\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "stepsize: 3000\n",
    "snapshot: 938\n",
    "snapshot_prefix: \"G:/workspace/caffe/mnist/lenet\"\n",
    "solver_mode: GPU\n",
    "type: \"SGD\"\n",
    "I0930 23:31:05.398864 14384 solver.cpp:81] Creating training net from train_net file: G:/workspace/caffe/mnist/train.prototxt\n",
    "I0930 23:31:05.399363 14384 net.cpp:58] Initializing net from parameters: \n",
    "state {\n",
    "  phase: TRAIN\n",
    "}\n",
    "layer {\n",
    "  name: \"ImageData1\"\n",
    "  type: \"ImageData\"\n",
    "  top: \"ImageData1\"\n",
    "  top: \"ImageData2\"\n",
    "  transform_param {\n",
    "    scale: 0.00390625\n",
    "  }\n",
    "  image_data_param {\n",
    "    source: \"G:/workspace/caffe/mnist/train/train.txt\"\n",
    "    batch_size: 64\n",
    "    root_folder: \"G:/workspace/caffe/\"\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Convolution1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"ImageData1\"\n",
    "  top: \"Convolution1\"\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    pad: 0\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Pooling1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"Convolution1\"\n",
    "  top: \"Pooling1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Convolution2\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"Pooling1\"\n",
    "  top: \"Convolution2\"\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    pad: 0\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Pooling2\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"Convolution2\"\n",
    "  top: \"Pooling2\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"InnerProduct1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"Pooling2\"\n",
    "  top: \"InnerProduct1\"\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ReLU1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"InnerProduct1\"\n",
    "  top: \"InnerProduct1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"InnerProduct2\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"InnerProduct1\"\n",
    "  top: \"InnerProduct2\"\n",
    "  inner_product_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"SoftmaxWithLoss1\"\n",
    "  type: \"SoftmaxWithLoss\"\n",
    "  bottom: \"InnerProduct2\"\n",
    "  bottom: \"ImageData2\"\n",
    "  top: \"SoftmaxWithLoss1\"\n",
    "}\n",
    "I0930 23:31:05.399363 14384 layer_factory.hpp:77] Creating layer ImageData1\n",
    "I0930 23:31:05.399363 14384 net.cpp:100] Creating Layer ImageData1\n",
    "I0930 23:31:05.399363 14384 net.cpp:418] ImageData1 -> ImageData1\n",
    "I0930 23:31:05.399363 14384 net.cpp:418] ImageData1 -> ImageData2\n",
    "I0930 23:31:05.399363 14384 image_data_layer.cpp:38] Opening file G:/workspace/caffe/mnist/train/train.txt\n",
    "I0930 23:31:05.434888 14384 image_data_layer.cpp:58] A total of 60000 images.\n",
    "I0930 23:31:09.229596 14384 image_data_layer.cpp:85] output data size: 64,3,28,28\n",
    "I0930 23:31:09.233099 14384 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.\n",
    "I0930 23:31:09.233099 14384 net.cpp:150] Setting up ImageData1\n",
    "I0930 23:31:09.233099 14384 net.cpp:157] Top shape: 64 3 28 28 (150528)\n",
    "I0930 23:31:09.233099 14384 net.cpp:157] Top shape: 64 (64)\n",
    "I0930 23:31:09.233099 14384 net.cpp:165] Memory required for data: 602368\n",
    "I0930 23:31:09.233099 14384 layer_factory.hpp:77] Creating layer Convolution1\n",
    "I0930 23:31:09.233099 14384 net.cpp:100] Creating Layer Convolution1\n",
    "I0930 23:31:09.233099 14384 net.cpp:444] Convolution1 <- ImageData1\n",
    "I0930 23:31:09.233099 14384 net.cpp:418] Convolution1 -> Convolution1\n",
    "I0930 23:31:09.235600 16160 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.\n",
    "I0930 23:31:10.603065 14384 net.cpp:150] Setting up Convolution1\n",
    "I0930 23:31:10.603565 14384 net.cpp:157] Top shape: 64 20 24 24 (737280)\n",
    "I0930 23:31:10.603565 14384 net.cpp:165] Memory required for data: 3551488\n",
    "I0930 23:31:10.608069 14384 layer_factory.hpp:77] Creating layer Pooling1\n",
    "I0930 23:31:10.608069 14384 net.cpp:100] Creating Layer Pooling1\n",
    "I0930 23:31:10.608069 14384 net.cpp:444] Pooling1 <- Convolution1\n",
    "I0930 23:31:10.608069 14384 net.cpp:418] Pooling1 -> Pooling1\n",
    "I0930 23:31:10.609071 14384 net.cpp:150] Setting up Pooling1\n",
    "I0930 23:31:10.609071 14384 net.cpp:157] Top shape: 64 20 12 12 (184320)\n",
    "I0930 23:31:10.609071 14384 net.cpp:165] Memory required for data: 4288768\n",
    "I0930 23:31:10.609071 14384 layer_factory.hpp:77] Creating layer Convolution2\n",
    "I0930 23:31:10.609071 14384 net.cpp:100] Creating Layer Convolution2\n",
    "I0930 23:31:10.609071 14384 net.cpp:444] Convolution2 <- Pooling1\n",
    "I0930 23:31:10.609071 14384 net.cpp:418] Convolution2 -> Convolution2\n",
    "I0930 23:31:10.613574 14384 net.cpp:150] Setting up Convolution2\n",
    "I0930 23:31:10.613574 14384 net.cpp:157] Top shape: 64 50 8 8 (204800)\n",
    "I0930 23:31:10.613574 14384 net.cpp:165] Memory required for data: 5107968\n",
    "I0930 23:31:10.614073 14384 layer_factory.hpp:77] Creating layer Pooling2\n",
    "I0930 23:31:10.614073 14384 net.cpp:100] Creating Layer Pooling2\n",
    "I0930 23:31:10.614073 14384 net.cpp:444] Pooling2 <- Convolution2\n",
    "I0930 23:31:10.614073 14384 net.cpp:418] Pooling2 -> Pooling2\n",
    "I0930 23:31:10.614073 14384 net.cpp:150] Setting up Pooling2\n",
    "I0930 23:31:10.614073 14384 net.cpp:157] Top shape: 64 50 4 4 (51200)\n",
    "I0930 23:31:10.614073 14384 net.cpp:165] Memory required for data: 5312768\n",
    "I0930 23:31:10.614073 14384 layer_factory.hpp:77] Creating layer InnerProduct1\n",
    "I0930 23:31:10.614073 14384 net.cpp:100] Creating Layer InnerProduct1\n",
    "I0930 23:31:10.614073 14384 net.cpp:444] InnerProduct1 <- Pooling2\n",
    "I0930 23:31:10.614073 14384 net.cpp:418] InnerProduct1 -> InnerProduct1\n",
    "I0930 23:31:10.617575 14384 net.cpp:150] Setting up InnerProduct1\n",
    "I0930 23:31:10.617575 14384 net.cpp:157] Top shape: 64 500 (32000)\n",
    "I0930 23:31:10.617575 14384 net.cpp:165] Memory required for data: 5440768\n",
    "I0930 23:31:10.617575 14384 layer_factory.hpp:77] Creating layer ReLU1\n",
    "I0930 23:31:10.617575 14384 net.cpp:100] Creating Layer ReLU1\n",
    "I0930 23:31:10.617575 14384 net.cpp:444] ReLU1 <- InnerProduct1\n",
    "I0930 23:31:10.617575 14384 net.cpp:405] ReLU1 -> InnerProduct1 (in-place)\n",
    "I0930 23:31:10.618075 14384 net.cpp:150] Setting up ReLU1\n",
    "I0930 23:31:10.618075 14384 net.cpp:157] Top shape: 64 500 (32000)\n",
    "I0930 23:31:10.618075 14384 net.cpp:165] Memory required for data: 5568768\n",
    "I0930 23:31:10.618577 14384 layer_factory.hpp:77] Creating layer InnerProduct2\n",
    "I0930 23:31:10.618577 14384 net.cpp:100] Creating Layer InnerProduct2\n",
    "I0930 23:31:10.618577 14384 net.cpp:444] InnerProduct2 <- InnerProduct1\n",
    "I0930 23:31:10.618577 14384 net.cpp:418] InnerProduct2 -> InnerProduct2\n",
    "I0930 23:31:10.619076 14384 net.cpp:150] Setting up InnerProduct2\n",
    "I0930 23:31:10.619076 14384 net.cpp:157] Top shape: 64 10 (640)\n",
    "I0930 23:31:10.619076 14384 net.cpp:165] Memory required for data: 5571328\n",
    "I0930 23:31:10.619076 14384 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1\n",
    "I0930 23:31:10.619076 14384 net.cpp:100] Creating Layer SoftmaxWithLoss1\n",
    "I0930 23:31:10.619076 14384 net.cpp:444] SoftmaxWithLoss1 <- InnerProduct2\n",
    "I0930 23:31:10.619076 14384 net.cpp:444] SoftmaxWithLoss1 <- ImageData2\n",
    "I0930 23:31:10.619076 14384 net.cpp:418] SoftmaxWithLoss1 -> SoftmaxWithLoss1\n",
    "I0930 23:31:10.619076 14384 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1\n",
    "I0930 23:31:10.619576 14384 net.cpp:150] Setting up SoftmaxWithLoss1\n",
    "I0930 23:31:10.619576 14384 net.cpp:157] Top shape: (1)\n",
    "I0930 23:31:10.619576 14384 net.cpp:160]     with loss weight 1\n",
    "I0930 23:31:10.621079 14384 net.cpp:165] Memory required for data: 5571332\n",
    "I0930 23:31:10.621079 14384 net.cpp:226] SoftmaxWithLoss1 needs backward computation.\n",
    "I0930 23:31:10.621079 14384 net.cpp:226] InnerProduct2 needs backward computation.\n",
    "I0930 23:31:10.621079 14384 net.cpp:226] ReLU1 needs backward computation.\n",
    "I0930 23:31:10.621079 14384 net.cpp:226] InnerProduct1 needs backward computation.\n",
    "I0930 23:31:10.621079 14384 net.cpp:226] Pooling2 needs backward computation.\n",
    "I0930 23:31:10.621079 14384 net.cpp:226] Convolution2 needs backward computation.\n",
    "I0930 23:31:10.622581 14384 net.cpp:226] Pooling1 needs backward computation.\n",
    "I0930 23:31:10.622581 14384 net.cpp:226] Convolution1 needs backward computation.\n",
    "I0930 23:31:10.622581 14384 net.cpp:228] ImageData1 does not need backward computation.\n",
    "I0930 23:31:10.622581 14384 net.cpp:270] This network produces output SoftmaxWithLoss1\n",
    "I0930 23:31:10.622581 14384 net.cpp:283] Network initialization done.\n",
    "I0930 23:31:10.622581 14384 solver.cpp:181] Creating test net (#0) specified by test_net file: G:/workspace/caffe/mnist/test.prototxt\n",
    "I0930 23:31:10.623080 14384 net.cpp:58] Initializing net from parameters: \n",
    "state {\n",
    "  phase: TEST\n",
    "}\n",
    "layer {\n",
    "  name: \"ImageData1\"\n",
    "  type: \"ImageData\"\n",
    "  top: \"ImageData1\"\n",
    "  top: \"ImageData2\"\n",
    "  transform_param {\n",
    "    scale: 0.00390625\n",
    "  }\n",
    "  image_data_param {\n",
    "    source: \"G:/workspace/caffe/mnist/test/test.txt\"\n",
    "    batch_size: 100\n",
    "    root_folder: \"G:/workspace/caffe/\"\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Convolution1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"ImageData1\"\n",
    "  top: \"Convolution1\"\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    pad: 0\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Pooling1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"Convolution1\"\n",
    "  top: \"Pooling1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Convolution2\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"Pooling1\"\n",
    "  top: \"Convolution2\"\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    pad: 0\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Pooling2\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"Convolution2\"\n",
    "  top: \"Pooling2\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"InnerProduct1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"Pooling2\"\n",
    "  top: \"InnerProduct1\"\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ReLU1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"InnerProduct1\"\n",
    "  top: \"InnerProduct1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"InnerProduct2\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"InnerProduct1\"\n",
    "  top: \"InnerProduct2\"\n",
    "  inner_product_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"SoftmaxWithLoss1\"\n",
    "  type: \"SoftmaxWithLoss\"\n",
    "  bottom: \"InnerProduct2\"\n",
    "  bottom: \"ImageData2\"\n",
    "  top: \"SoftmaxWithLoss1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"Accuracy1\"\n",
    "  type: \"Accuracy\"\n",
    "  bottom: \"InnerProduct2\"\n",
    "  bottom: \"ImageData2\"\n",
    "  top: \"Accuracy1\"\n",
    "}\n",
    "I0930 23:31:10.623080 14384 layer_factory.hpp:77] Creating layer ImageData1\n",
    "I0930 23:31:10.623080 14384 net.cpp:100] Creating Layer ImageData1\n",
    "I0930 23:31:10.623080 14384 net.cpp:418] ImageData1 -> ImageData1\n",
    "I0930 23:31:10.623080 14384 net.cpp:418] ImageData1 -> ImageData2\n",
    "I0930 23:31:10.623080 14384 image_data_layer.cpp:38] Opening file G:/workspace/caffe/mnist/test/test.txt\n",
    "I0930 23:31:10.630584 14384 image_data_layer.cpp:58] A total of 10000 images.\n",
    "I0930 23:31:10.631084 14384 image_data_layer.cpp:85] output data size: 100,3,28,28\n",
    "I0930 23:31:10.635901 14384 net.cpp:150] Setting up ImageData1\n",
    "I0930 23:31:10.635901 14384 net.cpp:157] Top shape: 100 3 28 28 (235200)\n",
    "I0930 23:31:10.635901 14384 net.cpp:157] Top shape: 100 (100)\n",
    "I0930 23:31:10.635901 14384 net.cpp:165] Memory required for data: 941200\n",
    "I0930 23:31:10.635901 14384 layer_factory.hpp:77] Creating layer ImageData2_ImageData1_1_split\n",
    "I0930 23:31:10.635901 14384 net.cpp:100] Creating Layer ImageData2_ImageData1_1_split\n",
    "I0930 23:31:10.635901 14384 net.cpp:444] ImageData2_ImageData1_1_split <- ImageData2\n",
    "I0930 23:31:10.635901 14384 net.cpp:418] ImageData2_ImageData1_1_split -> ImageData2_ImageData1_1_split_0\n",
    "I0930 23:31:10.635901 14384 net.cpp:418] ImageData2_ImageData1_1_split -> ImageData2_ImageData1_1_split_1\n",
    "I0930 23:31:10.636404 14384 net.cpp:150] Setting up ImageData2_ImageData1_1_split\n",
    "I0930 23:31:10.636404 14384 net.cpp:157] Top shape: 100 (100)\n",
    "I0930 23:31:10.636404 14384 net.cpp:157] Top shape: 100 (100)\n",
    "I0930 23:31:10.636404 14384 net.cpp:165] Memory required for data: 942000\n",
    "I0930 23:31:10.636404 14384 layer_factory.hpp:77] Creating layer Convolution1\n",
    "I0930 23:31:10.637403  1136 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.\n",
    "I0930 23:31:10.639405 14384 net.cpp:100] Creating Layer Convolution1\n",
    "I0930 23:31:10.639405 14384 net.cpp:444] Convolution1 <- ImageData1\n",
    "I0930 23:31:10.639405 14384 net.cpp:418] Convolution1 -> Convolution1\n",
    "I0930 23:31:10.642907 14384 net.cpp:150] Setting up Convolution1\n",
    "I0930 23:31:10.642907 14384 net.cpp:157] Top shape: 100 20 24 24 (1152000)\n",
    "I0930 23:31:10.642907 14384 net.cpp:165] Memory required for data: 5550000\n",
    "I0930 23:31:10.642907 14384 layer_factory.hpp:77] Creating layer Pooling1\n",
    "I0930 23:31:10.642907 14384 net.cpp:100] Creating Layer Pooling1\n",
    "I0930 23:31:10.642907 14384 net.cpp:444] Pooling1 <- Convolution1\n",
    "I0930 23:31:10.642907 14384 net.cpp:418] Pooling1 -> Pooling1\n",
    "I0930 23:31:10.643409 14384 net.cpp:150] Setting up Pooling1\n",
    "I0930 23:31:10.643409 14384 net.cpp:157] Top shape: 100 20 12 12 (288000)\n",
    "I0930 23:31:10.643409 14384 net.cpp:165] Memory required for data: 6702000\n",
    "I0930 23:31:10.643409 14384 layer_factory.hpp:77] Creating layer Convolution2\n",
    "I0930 23:31:10.643409 14384 net.cpp:100] Creating Layer Convolution2\n",
    "I0930 23:31:10.643409 14384 net.cpp:444] Convolution2 <- Pooling1\n",
    "I0930 23:31:10.643409 14384 net.cpp:418] Convolution2 -> Convolution2\n",
    "I0930 23:31:10.646410 14384 net.cpp:150] Setting up Convolution2\n",
    "I0930 23:31:10.646410 14384 net.cpp:157] Top shape: 100 50 8 8 (320000)\n",
    "I0930 23:31:10.646410 14384 net.cpp:165] Memory required for data: 7982000\n",
    "I0930 23:31:10.646410 14384 layer_factory.hpp:77] Creating layer Pooling2\n",
    "I0930 23:31:10.646410 14384 net.cpp:100] Creating Layer Pooling2\n",
    "I0930 23:31:10.646410 14384 net.cpp:444] Pooling2 <- Convolution2\n",
    "I0930 23:31:10.646410 14384 net.cpp:418] Pooling2 -> Pooling2\n",
    "I0930 23:31:10.646910 14384 net.cpp:150] Setting up Pooling2\n",
    "I0930 23:31:10.646910 14384 net.cpp:157] Top shape: 100 50 4 4 (80000)\n",
    "I0930 23:31:10.646910 14384 net.cpp:165] Memory required for data: 8302000\n",
    "I0930 23:31:10.646910 14384 layer_factory.hpp:77] Creating layer InnerProduct1\n",
    "I0930 23:31:10.646910 14384 net.cpp:100] Creating Layer InnerProduct1\n",
    "I0930 23:31:10.646910 14384 net.cpp:444] InnerProduct1 <- Pooling2\n",
    "I0930 23:31:10.646910 14384 net.cpp:418] InnerProduct1 -> InnerProduct1\n",
    "I0930 23:31:10.651914 14384 net.cpp:150] Setting up InnerProduct1\n",
    "I0930 23:31:10.651914 14384 net.cpp:157] Top shape: 100 500 (50000)\n",
    "I0930 23:31:10.651914 14384 net.cpp:165] Memory required for data: 8502000\n",
    "I0930 23:31:10.651914 14384 layer_factory.hpp:77] Creating layer ReLU1\n",
    "I0930 23:31:10.651914 14384 net.cpp:100] Creating Layer ReLU1\n",
    "I0930 23:31:10.651914 14384 net.cpp:444] ReLU1 <- InnerProduct1\n",
    "I0930 23:31:10.651914 14384 net.cpp:405] ReLU1 -> InnerProduct1 (in-place)\n",
    "I0930 23:31:10.653414 14384 net.cpp:150] Setting up ReLU1\n",
    "I0930 23:31:10.653414 14384 net.cpp:157] Top shape: 100 500 (50000)\n",
    "I0930 23:31:10.653414 14384 net.cpp:165] Memory required for data: 8702000\n",
    "I0930 23:31:10.653414 14384 layer_factory.hpp:77] Creating layer InnerProduct2\n",
    "I0930 23:31:10.653414 14384 net.cpp:100] Creating Layer InnerProduct2\n",
    "I0930 23:31:10.653414 14384 net.cpp:444] InnerProduct2 <- InnerProduct1\n",
    "I0930 23:31:10.653414 14384 net.cpp:418] InnerProduct2 -> InnerProduct2\n",
    "I0930 23:31:10.653916 14384 net.cpp:150] Setting up InnerProduct2\n",
    "I0930 23:31:10.653916 14384 net.cpp:157] Top shape: 100 10 (1000)\n",
    "I0930 23:31:10.653916 14384 net.cpp:165] Memory required for data: 8706000\n",
    "I0930 23:31:10.653916 14384 layer_factory.hpp:77] Creating layer InnerProduct2_InnerProduct2_0_split\n",
    "I0930 23:31:10.653916 14384 net.cpp:100] Creating Layer InnerProduct2_InnerProduct2_0_split\n",
    "I0930 23:31:10.653916 14384 net.cpp:444] InnerProduct2_InnerProduct2_0_split <- InnerProduct2\n",
    "I0930 23:31:10.653916 14384 net.cpp:418] InnerProduct2_InnerProduct2_0_split -> InnerProduct2_InnerProduct2_0_split_0\n",
    "I0930 23:31:10.653916 14384 net.cpp:418] InnerProduct2_InnerProduct2_0_split -> InnerProduct2_InnerProduct2_0_split_1\n",
    "I0930 23:31:10.653916 14384 net.cpp:150] Setting up InnerProduct2_InnerProduct2_0_split\n",
    "I0930 23:31:10.656918 14384 net.cpp:157] Top shape: 100 10 (1000)\n",
    "I0930 23:31:10.656918 14384 net.cpp:157] Top shape: 100 10 (1000)\n",
    "I0930 23:31:10.656918 14384 net.cpp:165] Memory required for data: 8714000\n",
    "I0930 23:31:10.656918 14384 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1\n",
    "I0930 23:31:10.656918 14384 net.cpp:100] Creating Layer SoftmaxWithLoss1\n",
    "I0930 23:31:10.656918 14384 net.cpp:444] SoftmaxWithLoss1 <- InnerProduct2_InnerProduct2_0_split_0\n",
    "I0930 23:31:10.656918 14384 net.cpp:444] SoftmaxWithLoss1 <- ImageData2_ImageData1_1_split_0\n",
    "I0930 23:31:10.656918 14384 net.cpp:418] SoftmaxWithLoss1 -> SoftmaxWithLoss1\n",
    "I0930 23:31:10.656918 14384 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1\n",
    "I0930 23:31:10.657418 14384 net.cpp:150] Setting up SoftmaxWithLoss1\n",
    "I0930 23:31:10.657418 14384 net.cpp:157] Top shape: (1)\n",
    "I0930 23:31:10.657418 14384 net.cpp:160]     with loss weight 1\n",
    "I0930 23:31:10.657418 14384 net.cpp:165] Memory required for data: 8714004\n",
    "I0930 23:31:10.657418 14384 layer_factory.hpp:77] Creating layer Accuracy1\n",
    "I0930 23:31:10.657418 14384 net.cpp:100] Creating Layer Accuracy1\n",
    "I0930 23:31:10.657418 14384 net.cpp:444] Accuracy1 <- InnerProduct2_InnerProduct2_0_split_1\n",
    "I0930 23:31:10.657418 14384 net.cpp:444] Accuracy1 <- ImageData2_ImageData1_1_split_1\n",
    "I0930 23:31:10.657418 14384 net.cpp:418] Accuracy1 -> Accuracy1\n",
    "I0930 23:31:10.657418 14384 net.cpp:150] Setting up Accuracy1\n",
    "I0930 23:31:10.657918 14384 net.cpp:157] Top shape: (1)\n",
    "I0930 23:31:10.657918 14384 net.cpp:165] Memory required for data: 8714008\n",
    "I0930 23:31:10.657918 14384 net.cpp:228] Accuracy1 does not need backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:226] SoftmaxWithLoss1 needs backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:226] InnerProduct2_InnerProduct2_0_split needs backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:226] InnerProduct2 needs backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:226] ReLU1 needs backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:226] InnerProduct1 needs backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:226] Pooling2 needs backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:226] Convolution2 needs backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:226] Pooling1 needs backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:226] Convolution1 needs backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:228] ImageData2_ImageData1_1_split does not need backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:228] ImageData1 does not need backward computation.\n",
    "I0930 23:31:10.657918 14384 net.cpp:270] This network produces output Accuracy1\n",
    "I0930 23:31:10.657918 14384 net.cpp:270] This network produces output SoftmaxWithLoss1\n",
    "I0930 23:31:10.657918 14384 net.cpp:283] Network initialization done.\n",
    "I0930 23:31:10.657918 14384 solver.cpp:60] Solver scaffolding done.\n",
    "I0930 23:31:10.658920 14384 solver.cpp:279] Solving \n",
    "I0930 23:31:10.658920 14384 solver.cpp:280] Learning Rate Policy: step\n",
    "I0930 23:31:10.676432 14384 solver.cpp:337] Iteration 0, Testing net (#0)\n",
    "I0930 23:31:10.702450 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:31:17.207540 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.1396\n",
    "I0930 23:31:17.207540 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 2.345 (* 1 = 2.345 loss)\n",
    "I0930 23:31:17.221549 14384 solver.cpp:228] Iteration 0, loss = 2.34329\n",
    "I0930 23:31:17.221549 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 2.34329 (* 1 = 2.34329 loss)\n",
    "I0930 23:31:17.221549 14384 sgd_solver.cpp:106] Iteration 0, lr = 0.01\n",
    "I0930 23:31:17.399675 14384 solver.cpp:228] Iteration 20, loss = 0.670338\n",
    "I0930 23:31:17.399675 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.670338 (* 1 = 0.670338 loss)\n",
    "I0930 23:31:17.399675 14384 sgd_solver.cpp:106] Iteration 20, lr = 0.01\n",
    "I0930 23:31:17.615828 14384 solver.cpp:228] Iteration 40, loss = 0.279443\n",
    "I0930 23:31:17.616328 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.279443 (* 1 = 0.279443 loss)\n",
    "I0930 23:31:17.619330 14384 sgd_solver.cpp:106] Iteration 40, lr = 0.01\n",
    "I0930 23:31:17.783445 14384 solver.cpp:228] Iteration 60, loss = 0.254836\n",
    "I0930 23:31:17.783445 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.254836 (* 1 = 0.254836 loss)\n",
    "I0930 23:31:17.783946 14384 sgd_solver.cpp:106] Iteration 60, lr = 0.01\n",
    "I0930 23:31:17.952064 14384 solver.cpp:228] Iteration 80, loss = 0.520101\n",
    "I0930 23:31:17.952064 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.520101 (* 1 = 0.520101 loss)\n",
    "I0930 23:31:17.952064 14384 sgd_solver.cpp:106] Iteration 80, lr = 0.01\n",
    "I0930 23:31:18.109676 14384 solver.cpp:228] Iteration 100, loss = 0.178719\n",
    "I0930 23:31:18.109676 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.178719 (* 1 = 0.178719 loss)\n",
    "I0930 23:31:18.109676 14384 sgd_solver.cpp:106] Iteration 100, lr = 0.01\n",
    "I0930 23:31:18.249274 14384 solver.cpp:228] Iteration 120, loss = 0.171421\n",
    "I0930 23:31:18.249274 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.171421 (* 1 = 0.171421 loss)\n",
    "I0930 23:31:18.249274 14384 sgd_solver.cpp:106] Iteration 120, lr = 0.01\n",
    "I0930 23:31:18.406386 14384 solver.cpp:228] Iteration 140, loss = 0.189807\n",
    "I0930 23:31:18.406386 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.189807 (* 1 = 0.189807 loss)\n",
    "I0930 23:31:18.406386 14384 sgd_solver.cpp:106] Iteration 140, lr = 0.01\n",
    "I0930 23:31:18.563496 14384 solver.cpp:228] Iteration 160, loss = 0.257215\n",
    "I0930 23:31:18.563496 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.257215 (* 1 = 0.257215 loss)\n",
    "I0930 23:31:18.563496 14384 sgd_solver.cpp:106] Iteration 160, lr = 0.01\n",
    "I0930 23:31:18.709100 14384 solver.cpp:228] Iteration 180, loss = 0.366439\n",
    "I0930 23:31:18.709100 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.366439 (* 1 = 0.366439 loss)\n",
    "I0930 23:31:18.709100 14384 sgd_solver.cpp:106] Iteration 180, lr = 0.01\n",
    "I0930 23:31:18.916746 14384 solver.cpp:228] Iteration 200, loss = 0.186772\n",
    "I0930 23:31:18.916746 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186772 (* 1 = 0.186772 loss)\n",
    "I0930 23:31:18.916746 14384 sgd_solver.cpp:106] Iteration 200, lr = 0.01\n",
    "I0930 23:31:19.205449 14384 solver.cpp:228] Iteration 220, loss = 0.143284\n",
    "I0930 23:31:19.205449 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143284 (* 1 = 0.143284 loss)\n",
    "I0930 23:31:19.205449 14384 sgd_solver.cpp:106] Iteration 220, lr = 0.01\n",
    "I0930 23:31:19.564702 14384 solver.cpp:228] Iteration 240, loss = 0.19647\n",
    "I0930 23:31:19.564702 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.19647 (* 1 = 0.19647 loss)\n",
    "I0930 23:31:19.564702 14384 sgd_solver.cpp:106] Iteration 240, lr = 0.01\n",
    "I0930 23:31:19.707304 14384 solver.cpp:228] Iteration 260, loss = 0.246472\n",
    "I0930 23:31:19.707304 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.246473 (* 1 = 0.246473 loss)\n",
    "I0930 23:31:19.707304 14384 sgd_solver.cpp:106] Iteration 260, lr = 0.01\n",
    "I0930 23:31:19.846901 14384 solver.cpp:228] Iteration 280, loss = 0.167574\n",
    "I0930 23:31:19.846901 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.167574 (* 1 = 0.167574 loss)\n",
    "I0930 23:31:19.846901 14384 sgd_solver.cpp:106] Iteration 280, lr = 0.01\n",
    "I0930 23:31:19.989001 14384 solver.cpp:228] Iteration 300, loss = 0.160412\n",
    "I0930 23:31:19.989001 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.160412 (* 1 = 0.160412 loss)\n",
    "I0930 23:31:19.989001 14384 sgd_solver.cpp:106] Iteration 300, lr = 0.01\n",
    "I0930 23:31:20.128100 14384 solver.cpp:228] Iteration 320, loss = 0.0407074\n",
    "I0930 23:31:20.128100 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0407075 (* 1 = 0.0407075 loss)\n",
    "I0930 23:31:20.128100 14384 sgd_solver.cpp:106] Iteration 320, lr = 0.01\n",
    "I0930 23:31:20.289214 14384 solver.cpp:228] Iteration 340, loss = 0.0252753\n",
    "I0930 23:31:20.289214 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0252754 (* 1 = 0.0252754 loss)\n",
    "I0930 23:31:20.289214 14384 sgd_solver.cpp:106] Iteration 340, lr = 0.01\n",
    "I0930 23:31:20.423308 14384 solver.cpp:228] Iteration 360, loss = 0.168279\n",
    "I0930 23:31:20.427811 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168279 (* 1 = 0.168279 loss)\n",
    "I0930 23:31:20.427811 14384 sgd_solver.cpp:106] Iteration 360, lr = 0.01\n",
    "I0930 23:31:20.565909 14384 solver.cpp:228] Iteration 380, loss = 0.0121611\n",
    "I0930 23:31:20.565909 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0121612 (* 1 = 0.0121612 loss)\n",
    "I0930 23:31:20.565909 14384 sgd_solver.cpp:106] Iteration 380, lr = 0.01\n",
    "I0930 23:31:20.750540 14384 solver.cpp:228] Iteration 400, loss = 0.0486779\n",
    "I0930 23:31:20.750540 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0486779 (* 1 = 0.0486779 loss)\n",
    "I0930 23:31:20.750540 14384 sgd_solver.cpp:106] Iteration 400, lr = 0.01\n",
    "I0930 23:31:20.903647 14384 solver.cpp:228] Iteration 420, loss = 0.220291\n",
    "I0930 23:31:20.903647 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.220291 (* 1 = 0.220291 loss)\n",
    "I0930 23:31:20.903647 14384 sgd_solver.cpp:106] Iteration 420, lr = 0.01\n",
    "I0930 23:31:21.061259 14384 solver.cpp:228] Iteration 440, loss = 0.0874218\n",
    "I0930 23:31:21.061259 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0874219 (* 1 = 0.0874219 loss)\n",
    "I0930 23:31:21.061259 14384 sgd_solver.cpp:106] Iteration 440, lr = 0.01\n",
    "I0930 23:31:21.227876 14384 solver.cpp:228] Iteration 460, loss = 0.0384856\n",
    "I0930 23:31:21.227876 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0384856 (* 1 = 0.0384856 loss)\n",
    "I0930 23:31:21.227876 14384 sgd_solver.cpp:106] Iteration 460, lr = 0.01\n",
    "I0930 23:31:21.390991 14384 solver.cpp:228] Iteration 480, loss = 0.0338859\n",
    "I0930 23:31:21.390991 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.033886 (* 1 = 0.033886 loss)\n",
    "I0930 23:31:21.390991 14384 sgd_solver.cpp:106] Iteration 480, lr = 0.01\n",
    "I0930 23:31:21.612148 14384 solver.cpp:228] Iteration 500, loss = 0.0966873\n",
    "I0930 23:31:21.612148 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0966873 (* 1 = 0.0966873 loss)\n",
    "I0930 23:31:21.612148 14384 sgd_solver.cpp:106] Iteration 500, lr = 0.01\n",
    "I0930 23:31:21.750744 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:31:21.794275 14384 solver.cpp:228] Iteration 520, loss = 0.163439\n",
    "I0930 23:31:21.794275 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.16344 (* 1 = 0.16344 loss)\n",
    "I0930 23:31:21.794275 14384 sgd_solver.cpp:106] Iteration 520, lr = 0.01\n",
    "I0930 23:31:21.937377 14384 solver.cpp:228] Iteration 540, loss = 0.104878\n",
    "I0930 23:31:21.937377 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.104878 (* 1 = 0.104878 loss)\n",
    "I0930 23:31:21.937377 14384 sgd_solver.cpp:106] Iteration 540, lr = 0.01\n",
    "I0930 23:31:22.075474 14384 solver.cpp:228] Iteration 560, loss = 0.173963\n",
    "I0930 23:31:22.075474 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.173963 (* 1 = 0.173963 loss)\n",
    "I0930 23:31:22.075474 14384 sgd_solver.cpp:106] Iteration 560, lr = 0.01\n",
    "I0930 23:31:22.226580 14384 solver.cpp:228] Iteration 580, loss = 0.0824516\n",
    "I0930 23:31:22.226580 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0824516 (* 1 = 0.0824516 loss)\n",
    "I0930 23:31:22.226580 14384 sgd_solver.cpp:106] Iteration 580, lr = 0.01\n",
    "I0930 23:31:22.387195 14384 solver.cpp:228] Iteration 600, loss = 0.0616129\n",
    "I0930 23:31:22.387694 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0616129 (* 1 = 0.0616129 loss)\n",
    "I0930 23:31:22.387694 14384 sgd_solver.cpp:106] Iteration 600, lr = 0.01\n",
    "I0930 23:31:22.552810 14384 solver.cpp:228] Iteration 620, loss = 0.121851\n",
    "I0930 23:31:22.552810 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.121851 (* 1 = 0.121851 loss)\n",
    "I0930 23:31:22.552810 14384 sgd_solver.cpp:106] Iteration 620, lr = 0.01\n",
    "I0930 23:31:22.712924 14384 solver.cpp:228] Iteration 640, loss = 0.190766\n",
    "I0930 23:31:22.712924 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.190767 (* 1 = 0.190767 loss)\n",
    "I0930 23:31:22.712924 14384 sgd_solver.cpp:106] Iteration 640, lr = 0.01\n",
    "I0930 23:31:22.892232 14384 solver.cpp:228] Iteration 660, loss = 0.00593593\n",
    "I0930 23:31:22.892232 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00593599 (* 1 = 0.00593599 loss)\n",
    "I0930 23:31:22.892232 14384 sgd_solver.cpp:106] Iteration 660, lr = 0.01\n",
    "I0930 23:31:23.398589 14384 solver.cpp:228] Iteration 680, loss = 0.131866\n",
    "I0930 23:31:23.398589 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131866 (* 1 = 0.131866 loss)\n",
    "I0930 23:31:23.398589 14384 sgd_solver.cpp:106] Iteration 680, lr = 0.01\n",
    "I0930 23:31:23.735327 14384 solver.cpp:228] Iteration 700, loss = 0.113641\n",
    "I0930 23:31:23.735327 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.113641 (* 1 = 0.113641 loss)\n",
    "I0930 23:31:23.735327 14384 sgd_solver.cpp:106] Iteration 700, lr = 0.01\n",
    "I0930 23:31:23.949477 14384 solver.cpp:228] Iteration 720, loss = 0.139017\n",
    "I0930 23:31:23.949477 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.139017 (* 1 = 0.139017 loss)\n",
    "I0930 23:31:23.949980 14384 sgd_solver.cpp:106] Iteration 720, lr = 0.01\n",
    "I0930 23:31:24.109091 14384 solver.cpp:228] Iteration 740, loss = 0.131803\n",
    "I0930 23:31:24.109091 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.131803 (* 1 = 0.131803 loss)\n",
    "I0930 23:31:24.109091 14384 sgd_solver.cpp:106] Iteration 740, lr = 0.01\n",
    "I0930 23:31:24.269203 14384 solver.cpp:228] Iteration 760, loss = 0.0397443\n",
    "I0930 23:31:24.269203 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0397443 (* 1 = 0.0397443 loss)\n",
    "I0930 23:31:24.269203 14384 sgd_solver.cpp:106] Iteration 760, lr = 0.01\n",
    "I0930 23:31:24.424813 14384 solver.cpp:228] Iteration 780, loss = 0.0860682\n",
    "I0930 23:31:24.424813 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0860682 (* 1 = 0.0860682 loss)\n",
    "I0930 23:31:24.424813 14384 sgd_solver.cpp:106] Iteration 780, lr = 0.01\n",
    "I0930 23:31:24.569416 14384 solver.cpp:228] Iteration 800, loss = 0.186085\n",
    "I0930 23:31:24.569416 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.186085 (* 1 = 0.186085 loss)\n",
    "I0930 23:31:24.569416 14384 sgd_solver.cpp:106] Iteration 800, lr = 0.01\n",
    "I0930 23:31:24.702008 14384 solver.cpp:228] Iteration 820, loss = 0.0384218\n",
    "I0930 23:31:24.702008 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0384218 (* 1 = 0.0384218 loss)\n",
    "I0930 23:31:24.702008 14384 sgd_solver.cpp:106] Iteration 820, lr = 0.01\n",
    "I0930 23:31:24.836103 14384 solver.cpp:228] Iteration 840, loss = 0.0596828\n",
    "I0930 23:31:24.836103 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0596829 (* 1 = 0.0596829 loss)\n",
    "I0930 23:31:24.836103 14384 sgd_solver.cpp:106] Iteration 840, lr = 0.01\n",
    "I0930 23:31:24.977203 14384 solver.cpp:228] Iteration 860, loss = 0.0344183\n",
    "I0930 23:31:24.977203 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0344184 (* 1 = 0.0344184 loss)\n",
    "I0930 23:31:24.977203 14384 sgd_solver.cpp:106] Iteration 860, lr = 0.01\n",
    "I0930 23:31:25.111297 14384 solver.cpp:228] Iteration 880, loss = 0.0517879\n",
    "I0930 23:31:25.111297 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.051788 (* 1 = 0.051788 loss)\n",
    "I0930 23:31:25.111297 14384 sgd_solver.cpp:106] Iteration 880, lr = 0.01\n",
    "I0930 23:31:25.272912 14384 solver.cpp:228] Iteration 900, loss = 0.124252\n",
    "I0930 23:31:25.272912 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.124252 (* 1 = 0.124252 loss)\n",
    "I0930 23:31:25.272912 14384 sgd_solver.cpp:106] Iteration 900, lr = 0.01\n",
    "I0930 23:31:25.433526 14384 solver.cpp:228] Iteration 920, loss = 0.000729755\n",
    "I0930 23:31:25.433526 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000729846 (* 1 = 0.000729846 loss)\n",
    "I0930 23:31:25.433526 14384 sgd_solver.cpp:106] Iteration 920, lr = 0.01\n",
    "I0930 23:31:25.566120 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_938.caffemodel\n",
    "I0930 23:31:25.585633 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_938.solverstate\n",
    "I0930 23:31:25.594138 14384 solver.cpp:337] Iteration 938, Testing net (#0)\n",
    "I0930 23:31:32.237826 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9778\n",
    "I0930 23:31:32.237826 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0674018 (* 1 = 0.0674018 loss)\n",
    "I0930 23:31:32.256340 14384 solver.cpp:228] Iteration 940, loss = 0.148712\n",
    "I0930 23:31:32.256340 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.148712 (* 1 = 0.148712 loss)\n",
    "I0930 23:31:32.256340 14384 sgd_solver.cpp:106] Iteration 940, lr = 0.01\n",
    "I0930 23:31:32.434965 14384 solver.cpp:228] Iteration 960, loss = 0.00868696\n",
    "I0930 23:31:32.434965 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0086871 (* 1 = 0.0086871 loss)\n",
    "I0930 23:31:32.434965 14384 sgd_solver.cpp:106] Iteration 960, lr = 0.01\n",
    "I0930 23:31:32.616593 14384 solver.cpp:228] Iteration 980, loss = 0.120132\n",
    "I0930 23:31:32.616593 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.120132 (* 1 = 0.120132 loss)\n",
    "I0930 23:31:32.616593 14384 sgd_solver.cpp:106] Iteration 980, lr = 0.01\n",
    "I0930 23:31:32.781710 14384 solver.cpp:228] Iteration 1000, loss = 0.0479923\n",
    "I0930 23:31:32.782210 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0479925 (* 1 = 0.0479925 loss)\n",
    "I0930 23:31:32.782210 14384 sgd_solver.cpp:106] Iteration 1000, lr = 0.01\n",
    "I0930 23:31:32.960336 14384 solver.cpp:228] Iteration 1020, loss = 0.143357\n",
    "I0930 23:31:32.960336 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.143357 (* 1 = 0.143357 loss)\n",
    "I0930 23:31:32.960336 14384 sgd_solver.cpp:106] Iteration 1020, lr = 0.01\n",
    "I0930 23:31:32.989356 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:31:33.143965 14384 solver.cpp:228] Iteration 1040, loss = 0.0525475\n",
    "I0930 23:31:33.143965 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0525476 (* 1 = 0.0525476 loss)\n",
    "I0930 23:31:33.143965 14384 sgd_solver.cpp:106] Iteration 1040, lr = 0.01\n",
    "I0930 23:31:33.331097 14384 solver.cpp:228] Iteration 1060, loss = 0.0694372\n",
    "I0930 23:31:33.331097 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0694373 (* 1 = 0.0694373 loss)\n",
    "I0930 23:31:33.331097 14384 sgd_solver.cpp:106] Iteration 1060, lr = 0.01\n",
    "I0930 23:31:33.507221 14384 solver.cpp:228] Iteration 1080, loss = 0.0226298\n",
    "I0930 23:31:33.507221 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0226299 (* 1 = 0.0226299 loss)\n",
    "I0930 23:31:33.507221 14384 sgd_solver.cpp:106] Iteration 1080, lr = 0.01\n",
    "I0930 23:31:33.670336 14384 solver.cpp:228] Iteration 1100, loss = 0.0146224\n",
    "I0930 23:31:33.670336 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0146225 (* 1 = 0.0146225 loss)\n",
    "I0930 23:31:33.670336 14384 sgd_solver.cpp:106] Iteration 1100, lr = 0.01\n",
    "I0930 23:31:33.832952 14384 solver.cpp:228] Iteration 1120, loss = 0.0522399\n",
    "I0930 23:31:33.832952 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.05224 (* 1 = 0.05224 loss)\n",
    "I0930 23:31:33.832952 14384 sgd_solver.cpp:106] Iteration 1120, lr = 0.01\n",
    "I0930 23:31:33.993566 14384 solver.cpp:228] Iteration 1140, loss = 0.0677193\n",
    "I0930 23:31:33.994065 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0677194 (* 1 = 0.0677194 loss)\n",
    "I0930 23:31:33.994065 14384 sgd_solver.cpp:106] Iteration 1140, lr = 0.01\n",
    "I0930 23:31:34.160683 14384 solver.cpp:228] Iteration 1160, loss = 0.0258679\n",
    "I0930 23:31:34.161183 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.025868 (* 1 = 0.025868 loss)\n",
    "I0930 23:31:34.161183 14384 sgd_solver.cpp:106] Iteration 1160, lr = 0.01\n",
    "I0930 23:31:34.329802 14384 solver.cpp:228] Iteration 1180, loss = 0.0376118\n",
    "I0930 23:31:34.329802 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0376119 (* 1 = 0.0376119 loss)\n",
    "I0930 23:31:34.329802 14384 sgd_solver.cpp:106] Iteration 1180, lr = 0.01\n",
    "I0930 23:31:34.541952 14384 solver.cpp:228] Iteration 1200, loss = 0.0273135\n",
    "I0930 23:31:34.541952 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0273136 (* 1 = 0.0273136 loss)\n",
    "I0930 23:31:34.541952 14384 sgd_solver.cpp:106] Iteration 1200, lr = 0.01\n",
    "I0930 23:31:34.770613 14384 solver.cpp:228] Iteration 1220, loss = 0.0490581\n",
    "I0930 23:31:34.770613 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0490582 (* 1 = 0.0490582 loss)\n",
    "I0930 23:31:34.770613 14384 sgd_solver.cpp:106] Iteration 1220, lr = 0.01\n",
    "I0930 23:31:34.958746 14384 solver.cpp:228] Iteration 1240, loss = 0.0967202\n",
    "I0930 23:31:34.958746 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0967203 (* 1 = 0.0967203 loss)\n",
    "I0930 23:31:34.958746 14384 sgd_solver.cpp:106] Iteration 1240, lr = 0.01\n",
    "I0930 23:31:35.112354 14384 solver.cpp:228] Iteration 1260, loss = 0.127575\n",
    "I0930 23:31:35.112354 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.127576 (* 1 = 0.127576 loss)\n",
    "I0930 23:31:35.112354 14384 sgd_solver.cpp:106] Iteration 1260, lr = 0.01\n",
    "I0930 23:31:35.277971 14384 solver.cpp:228] Iteration 1280, loss = 0.0443074\n",
    "I0930 23:31:35.278471 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0443075 (* 1 = 0.0443075 loss)\n",
    "I0930 23:31:35.278471 14384 sgd_solver.cpp:106] Iteration 1280, lr = 0.01\n",
    "I0930 23:31:35.442086 14384 solver.cpp:228] Iteration 1300, loss = 0.0499943\n",
    "I0930 23:31:35.442086 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0499944 (* 1 = 0.0499944 loss)\n",
    "I0930 23:31:35.442086 14384 sgd_solver.cpp:106] Iteration 1300, lr = 0.01\n",
    "I0930 23:31:35.610705 14384 solver.cpp:228] Iteration 1320, loss = 0.085498\n",
    "I0930 23:31:35.610705 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0854981 (* 1 = 0.0854981 loss)\n",
    "I0930 23:31:35.610705 14384 sgd_solver.cpp:106] Iteration 1320, lr = 0.01\n",
    "I0930 23:31:35.751806 14384 solver.cpp:228] Iteration 1340, loss = 0.0544299\n",
    "I0930 23:31:35.751806 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.05443 (* 1 = 0.05443 loss)\n",
    "I0930 23:31:35.752305 14384 sgd_solver.cpp:106] Iteration 1340, lr = 0.01\n",
    "I0930 23:31:35.890403 14384 solver.cpp:228] Iteration 1360, loss = 0.0523411\n",
    "I0930 23:31:35.890403 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0523412 (* 1 = 0.0523412 loss)\n",
    "I0930 23:31:35.890403 14384 sgd_solver.cpp:106] Iteration 1360, lr = 0.01\n",
    "I0930 23:31:36.166599 14384 solver.cpp:228] Iteration 1380, loss = 0.0511638\n",
    "I0930 23:31:36.167098 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0511639 (* 1 = 0.0511639 loss)\n",
    "I0930 23:31:36.167098 14384 sgd_solver.cpp:106] Iteration 1380, lr = 0.01\n",
    "I0930 23:31:36.337718 14384 solver.cpp:228] Iteration 1400, loss = 0.0108788\n",
    "I0930 23:31:36.337718 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0108789 (* 1 = 0.0108789 loss)\n",
    "I0930 23:31:36.337718 14384 sgd_solver.cpp:106] Iteration 1400, lr = 0.01\n",
    "I0930 23:31:36.477818 14384 solver.cpp:228] Iteration 1420, loss = 0.0345859\n",
    "I0930 23:31:36.478318 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.034586 (* 1 = 0.034586 loss)\n",
    "I0930 23:31:36.478318 14384 sgd_solver.cpp:106] Iteration 1420, lr = 0.01\n",
    "I0930 23:31:36.631927 14384 solver.cpp:228] Iteration 1440, loss = 0.0140064\n",
    "I0930 23:31:36.631927 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0140066 (* 1 = 0.0140066 loss)\n",
    "I0930 23:31:36.631927 14384 sgd_solver.cpp:106] Iteration 1440, lr = 0.01\n",
    "I0930 23:31:36.782032 14384 solver.cpp:228] Iteration 1460, loss = 0.0151169\n",
    "I0930 23:31:36.782032 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0151171 (* 1 = 0.0151171 loss)\n",
    "I0930 23:31:36.782032 14384 sgd_solver.cpp:106] Iteration 1460, lr = 0.01\n",
    "I0930 23:31:36.921630 14384 solver.cpp:228] Iteration 1480, loss = 0.0855911\n",
    "I0930 23:31:36.921630 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0855912 (* 1 = 0.0855912 loss)\n",
    "I0930 23:31:36.921630 14384 sgd_solver.cpp:106] Iteration 1480, lr = 0.01\n",
    "I0930 23:31:37.075240 14384 solver.cpp:228] Iteration 1500, loss = 0.0475379\n",
    "I0930 23:31:37.075240 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.047538 (* 1 = 0.047538 loss)\n",
    "I0930 23:31:37.075240 14384 sgd_solver.cpp:106] Iteration 1500, lr = 0.01\n",
    "I0930 23:31:37.223343 14384 solver.cpp:228] Iteration 1520, loss = 0.0258675\n",
    "I0930 23:31:37.225844 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0258676 (* 1 = 0.0258676 loss)\n",
    "I0930 23:31:37.225844 14384 sgd_solver.cpp:106] Iteration 1520, lr = 0.01\n",
    "I0930 23:31:37.378953 14384 solver.cpp:228] Iteration 1540, loss = 0.0611887\n",
    "I0930 23:31:37.379454 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0611889 (* 1 = 0.0611889 loss)\n",
    "I0930 23:31:37.379454 14384 sgd_solver.cpp:106] Iteration 1540, lr = 0.01\n",
    "I0930 23:31:37.606613 14384 solver.cpp:228] Iteration 1560, loss = 0.102547\n",
    "I0930 23:31:37.606613 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.102547 (* 1 = 0.102547 loss)\n",
    "I0930 23:31:37.606613 14384 sgd_solver.cpp:106] Iteration 1560, lr = 0.01\n",
    "I0930 23:31:37.765727 14384 solver.cpp:228] Iteration 1580, loss = 0.0585646\n",
    "I0930 23:31:37.765727 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0585647 (* 1 = 0.0585647 loss)\n",
    "I0930 23:31:37.765727 14384 sgd_solver.cpp:106] Iteration 1580, lr = 0.01\n",
    "I0930 23:31:37.923837 14384 solver.cpp:228] Iteration 1600, loss = 0.103161\n",
    "I0930 23:31:37.923837 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.103161 (* 1 = 0.103161 loss)\n",
    "I0930 23:31:37.923837 14384 sgd_solver.cpp:106] Iteration 1600, lr = 0.01\n",
    "I0930 23:31:38.075444 14384 solver.cpp:228] Iteration 1620, loss = 0.0147944\n",
    "I0930 23:31:38.075444 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0147945 (* 1 = 0.0147945 loss)\n",
    "I0930 23:31:38.075444 14384 sgd_solver.cpp:106] Iteration 1620, lr = 0.01\n",
    "I0930 23:31:38.216544 14384 solver.cpp:228] Iteration 1640, loss = 0.0154131\n",
    "I0930 23:31:38.216544 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0154132 (* 1 = 0.0154132 loss)\n",
    "I0930 23:31:38.216544 14384 sgd_solver.cpp:106] Iteration 1640, lr = 0.01\n",
    "I0930 23:31:38.381661 14384 solver.cpp:228] Iteration 1660, loss = 0.258778\n",
    "I0930 23:31:38.381661 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.258778 (* 1 = 0.258778 loss)\n",
    "I0930 23:31:38.381661 14384 sgd_solver.cpp:106] Iteration 1660, lr = 0.01\n",
    "I0930 23:31:38.556784 14384 solver.cpp:228] Iteration 1680, loss = 0.00886124\n",
    "I0930 23:31:38.556784 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00886138 (* 1 = 0.00886138 loss)\n",
    "I0930 23:31:38.556784 14384 sgd_solver.cpp:106] Iteration 1680, lr = 0.01\n",
    "I0930 23:31:38.956568 14384 solver.cpp:228] Iteration 1700, loss = 0.0459384\n",
    "I0930 23:31:38.957069 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0459385 (* 1 = 0.0459385 loss)\n",
    "I0930 23:31:38.957069 14384 sgd_solver.cpp:106] Iteration 1700, lr = 0.01\n",
    "I0930 23:31:39.150203 14384 solver.cpp:228] Iteration 1720, loss = 0.00495211\n",
    "I0930 23:31:39.150203 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00495226 (* 1 = 0.00495226 loss)\n",
    "I0930 23:31:39.150203 14384 sgd_solver.cpp:106] Iteration 1720, lr = 0.01\n",
    "I0930 23:31:39.361852 14384 solver.cpp:228] Iteration 1740, loss = 0.00957766\n",
    "I0930 23:31:39.361852 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00957781 (* 1 = 0.00957781 loss)\n",
    "I0930 23:31:39.361852 14384 sgd_solver.cpp:106] Iteration 1740, lr = 0.01\n",
    "I0930 23:31:39.508956 14384 solver.cpp:228] Iteration 1760, loss = 0.0684483\n",
    "I0930 23:31:39.509457 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0684485 (* 1 = 0.0684485 loss)\n",
    "I0930 23:31:39.509457 14384 sgd_solver.cpp:106] Iteration 1760, lr = 0.01\n",
    "I0930 23:31:39.694087 14384 solver.cpp:228] Iteration 1780, loss = 0.0141578\n",
    "I0930 23:31:39.694087 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0141579 (* 1 = 0.0141579 loss)\n",
    "I0930 23:31:39.694087 14384 sgd_solver.cpp:106] Iteration 1780, lr = 0.01\n",
    "I0930 23:31:39.858703 14384 solver.cpp:228] Iteration 1800, loss = 0.0101942\n",
    "I0930 23:31:39.858703 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0101943 (* 1 = 0.0101943 loss)\n",
    "I0930 23:31:39.858703 14384 sgd_solver.cpp:106] Iteration 1800, lr = 0.01\n",
    "I0930 23:31:39.997802 14384 solver.cpp:228] Iteration 1820, loss = 0.0635592\n",
    "I0930 23:31:40.000303 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0635593 (* 1 = 0.0635593 loss)\n",
    "I0930 23:31:40.000303 14384 sgd_solver.cpp:106] Iteration 1820, lr = 0.01\n",
    "I0930 23:31:40.133396 14384 solver.cpp:228] Iteration 1840, loss = 0.0457117\n",
    "I0930 23:31:40.133396 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0457118 (* 1 = 0.0457118 loss)\n",
    "I0930 23:31:40.133396 14384 sgd_solver.cpp:106] Iteration 1840, lr = 0.01\n",
    "I0930 23:31:40.276499 14384 solver.cpp:228] Iteration 1860, loss = 0.000317861\n",
    "I0930 23:31:40.276499 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000317997 (* 1 = 0.000317997 loss)\n",
    "I0930 23:31:40.276499 14384 sgd_solver.cpp:106] Iteration 1860, lr = 0.01\n",
    "I0930 23:31:40.382572 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_1876.caffemodel\n",
    "I0930 23:31:40.397583 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_1876.solverstate\n",
    "I0930 23:31:40.404088 14384 solver.cpp:337] Iteration 1876, Testing net (#0)\n",
    "I0930 23:31:41.979710 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:31:46.261731 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9832\n",
    "I0930 23:31:46.261731 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.049112 (* 1 = 0.049112 loss)\n",
    "I0930 23:31:46.290752 14384 solver.cpp:228] Iteration 1880, loss = 0.0101461\n",
    "I0930 23:31:46.290752 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0101462 (* 1 = 0.0101462 loss)\n",
    "I0930 23:31:46.290752 14384 sgd_solver.cpp:106] Iteration 1880, lr = 0.01\n",
    "I0930 23:31:46.436856 14384 solver.cpp:228] Iteration 1900, loss = 0.117219\n",
    "I0930 23:31:46.436856 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.117219 (* 1 = 0.117219 loss)\n",
    "I0930 23:31:46.436856 14384 sgd_solver.cpp:106] Iteration 1900, lr = 0.01\n",
    "I0930 23:31:46.580456 14384 solver.cpp:228] Iteration 1920, loss = 0.0563945\n",
    "I0930 23:31:46.580456 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0563947 (* 1 = 0.0563947 loss)\n",
    "I0930 23:31:46.580456 14384 sgd_solver.cpp:106] Iteration 1920, lr = 0.01\n",
    "I0930 23:31:46.726559 14384 solver.cpp:228] Iteration 1940, loss = 0.0136634\n",
    "I0930 23:31:46.726559 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0136635 (* 1 = 0.0136635 loss)\n",
    "I0930 23:31:46.726559 14384 sgd_solver.cpp:106] Iteration 1940, lr = 0.01\n",
    "I0930 23:31:46.885172 14384 solver.cpp:228] Iteration 1960, loss = 0.0202315\n",
    "I0930 23:31:46.885172 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0202316 (* 1 = 0.0202316 loss)\n",
    "I0930 23:31:46.885172 14384 sgd_solver.cpp:106] Iteration 1960, lr = 0.01\n",
    "I0930 23:31:47.017766 14384 solver.cpp:228] Iteration 1980, loss = 0.00518534\n",
    "I0930 23:31:47.017766 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00518546 (* 1 = 0.00518546 loss)\n",
    "I0930 23:31:47.017766 14384 sgd_solver.cpp:106] Iteration 1980, lr = 0.01\n",
    "I0930 23:31:47.154861 14384 solver.cpp:228] Iteration 2000, loss = 0.00841633\n",
    "I0930 23:31:47.154861 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00841645 (* 1 = 0.00841645 loss)\n",
    "I0930 23:31:47.154861 14384 sgd_solver.cpp:106] Iteration 2000, lr = 0.01\n",
    "I0930 23:31:47.293459 14384 solver.cpp:228] Iteration 2020, loss = 0.010817\n",
    "I0930 23:31:47.293459 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0108171 (* 1 = 0.0108171 loss)\n",
    "I0930 23:31:47.293459 14384 sgd_solver.cpp:106] Iteration 2020, lr = 0.01\n",
    "I0930 23:31:47.448068 14384 solver.cpp:228] Iteration 2040, loss = 0.00308586\n",
    "I0930 23:31:47.448068 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00308597 (* 1 = 0.00308597 loss)\n",
    "I0930 23:31:47.448570 14384 sgd_solver.cpp:106] Iteration 2040, lr = 0.01\n",
    "I0930 23:31:47.669225 14384 solver.cpp:228] Iteration 2060, loss = 0.0362217\n",
    "I0930 23:31:47.669225 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0362218 (* 1 = 0.0362218 loss)\n",
    "I0930 23:31:47.669225 14384 sgd_solver.cpp:106] Iteration 2060, lr = 0.01\n",
    "I0930 23:31:47.812826 14384 solver.cpp:228] Iteration 2080, loss = 0.0106393\n",
    "I0930 23:31:47.812826 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0106394 (* 1 = 0.0106394 loss)\n",
    "I0930 23:31:47.812826 14384 sgd_solver.cpp:106] Iteration 2080, lr = 0.01\n",
    "I0930 23:31:47.962931 14384 solver.cpp:228] Iteration 2100, loss = 0.0448009\n",
    "I0930 23:31:47.962931 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.044801 (* 1 = 0.044801 loss)\n",
    "I0930 23:31:47.962931 14384 sgd_solver.cpp:106] Iteration 2100, lr = 0.01\n",
    "I0930 23:31:48.114539 14384 solver.cpp:228] Iteration 2120, loss = 0.0142098\n",
    "I0930 23:31:48.114539 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0142099 (* 1 = 0.0142099 loss)\n",
    "I0930 23:31:48.114539 14384 sgd_solver.cpp:106] Iteration 2120, lr = 0.01\n",
    "I0930 23:31:48.260143 14384 solver.cpp:228] Iteration 2140, loss = 0.0441349\n",
    "I0930 23:31:48.260143 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0441351 (* 1 = 0.0441351 loss)\n",
    "I0930 23:31:48.260143 14384 sgd_solver.cpp:106] Iteration 2140, lr = 0.01\n",
    "I0930 23:31:48.409247 14384 solver.cpp:228] Iteration 2160, loss = 0.00899376\n",
    "I0930 23:31:48.409247 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00899387 (* 1 = 0.00899387 loss)\n",
    "I0930 23:31:48.409247 14384 sgd_solver.cpp:106] Iteration 2160, lr = 0.01\n",
    "I0930 23:31:48.575865 14384 solver.cpp:228] Iteration 2180, loss = 0.0143169\n",
    "I0930 23:31:48.575865 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.014317 (* 1 = 0.014317 loss)\n",
    "I0930 23:31:48.575865 14384 sgd_solver.cpp:106] Iteration 2180, lr = 0.01\n",
    "I0930 23:31:48.768501 14384 solver.cpp:228] Iteration 2200, loss = 0.0148424\n",
    "I0930 23:31:48.768501 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0148425 (* 1 = 0.0148425 loss)\n",
    "I0930 23:31:48.768501 14384 sgd_solver.cpp:106] Iteration 2200, lr = 0.01\n",
    "I0930 23:31:48.946125 14384 solver.cpp:228] Iteration 2220, loss = 0.0122292\n",
    "I0930 23:31:48.946125 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0122293 (* 1 = 0.0122293 loss)\n",
    "I0930 23:31:48.946125 14384 sgd_solver.cpp:106] Iteration 2220, lr = 0.01\n",
    "I0930 23:31:49.123751 14384 solver.cpp:228] Iteration 2240, loss = 0.0227923\n",
    "I0930 23:31:49.123751 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0227924 (* 1 = 0.0227924 loss)\n",
    "I0930 23:31:49.123751 14384 sgd_solver.cpp:106] Iteration 2240, lr = 0.01\n",
    "I0930 23:31:49.290369 14384 solver.cpp:228] Iteration 2260, loss = 0.040967\n",
    "I0930 23:31:49.290369 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0409671 (* 1 = 0.0409671 loss)\n",
    "I0930 23:31:49.290369 14384 sgd_solver.cpp:106] Iteration 2260, lr = 0.01\n",
    "I0930 23:31:49.443477 14384 solver.cpp:228] Iteration 2280, loss = 0.0128692\n",
    "I0930 23:31:49.443977 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0128693 (* 1 = 0.0128693 loss)\n",
    "I0930 23:31:49.443977 14384 sgd_solver.cpp:106] Iteration 2280, lr = 0.01\n",
    "I0930 23:31:49.600591 14384 solver.cpp:228] Iteration 2300, loss = 0.118247\n",
    "I0930 23:31:49.600591 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.118247 (* 1 = 0.118247 loss)\n",
    "I0930 23:31:49.600591 14384 sgd_solver.cpp:106] Iteration 2300, lr = 0.01\n",
    "I0930 23:31:49.747695 14384 solver.cpp:228] Iteration 2320, loss = 0.0153536\n",
    "I0930 23:31:49.747695 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0153537 (* 1 = 0.0153537 loss)\n",
    "I0930 23:31:49.747695 14384 sgd_solver.cpp:106] Iteration 2320, lr = 0.01\n",
    "I0930 23:31:49.904805 14384 solver.cpp:228] Iteration 2340, loss = 0.00631407\n",
    "I0930 23:31:49.904805 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00631418 (* 1 = 0.00631418 loss)\n",
    "I0930 23:31:49.904805 14384 sgd_solver.cpp:106] Iteration 2340, lr = 0.01\n",
    "I0930 23:31:50.039400 14384 solver.cpp:228] Iteration 2360, loss = 0.0144677\n",
    "I0930 23:31:50.039400 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0144678 (* 1 = 0.0144678 loss)\n",
    "I0930 23:31:50.039400 14384 sgd_solver.cpp:106] Iteration 2360, lr = 0.01\n",
    "I0930 23:31:50.198012 14384 solver.cpp:228] Iteration 2380, loss = 0.168168\n",
    "I0930 23:31:50.198012 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.168168 (* 1 = 0.168168 loss)\n",
    "I0930 23:31:50.198012 14384 sgd_solver.cpp:106] Iteration 2380, lr = 0.01\n",
    "I0930 23:31:50.373136 14384 solver.cpp:228] Iteration 2400, loss = 0.0219257\n",
    "I0930 23:31:50.373136 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0219258 (* 1 = 0.0219258 loss)\n",
    "I0930 23:31:50.373136 14384 sgd_solver.cpp:106] Iteration 2400, lr = 0.01\n",
    "I0930 23:31:50.510233 14384 solver.cpp:228] Iteration 2420, loss = 0.0502915\n",
    "I0930 23:31:50.510233 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0502916 (* 1 = 0.0502916 loss)\n",
    "I0930 23:31:50.510233 14384 sgd_solver.cpp:106] Iteration 2420, lr = 0.01\n",
    "I0930 23:31:50.648330 14384 solver.cpp:228] Iteration 2440, loss = 0.0187686\n",
    "I0930 23:31:50.648330 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0187687 (* 1 = 0.0187687 loss)\n",
    "I0930 23:31:50.648330 14384 sgd_solver.cpp:106] Iteration 2440, lr = 0.01\n",
    "I0930 23:31:50.780424 14384 solver.cpp:228] Iteration 2460, loss = 0.0348798\n",
    "I0930 23:31:50.780424 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0348799 (* 1 = 0.0348799 loss)\n",
    "I0930 23:31:50.780424 14384 sgd_solver.cpp:106] Iteration 2460, lr = 0.01\n",
    "I0930 23:31:50.922525 14384 solver.cpp:228] Iteration 2480, loss = 0.0117494\n",
    "I0930 23:31:50.922525 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0117496 (* 1 = 0.0117496 loss)\n",
    "I0930 23:31:50.922525 14384 sgd_solver.cpp:106] Iteration 2480, lr = 0.01\n",
    "I0930 23:31:51.056618 14384 solver.cpp:228] Iteration 2500, loss = 0.0146882\n",
    "I0930 23:31:51.056618 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0146883 (* 1 = 0.0146883 loss)\n",
    "I0930 23:31:51.056618 14384 sgd_solver.cpp:106] Iteration 2500, lr = 0.01\n",
    "I0930 23:31:51.218233 14384 solver.cpp:228] Iteration 2520, loss = 0.0366037\n",
    "I0930 23:31:51.218233 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0366039 (* 1 = 0.0366039 loss)\n",
    "I0930 23:31:51.218233 14384 sgd_solver.cpp:106] Iteration 2520, lr = 0.01\n",
    "I0930 23:31:51.350325 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:31:51.356830 14384 solver.cpp:228] Iteration 2540, loss = 0.0617699\n",
    "I0930 23:31:51.356830 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0617701 (* 1 = 0.0617701 loss)\n",
    "I0930 23:31:51.356830 14384 sgd_solver.cpp:106] Iteration 2540, lr = 0.01\n",
    "I0930 23:31:51.506937 14384 solver.cpp:228] Iteration 2560, loss = 0.0359817\n",
    "I0930 23:31:51.506937 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0359818 (* 1 = 0.0359818 loss)\n",
    "I0930 23:31:51.506937 14384 sgd_solver.cpp:106] Iteration 2560, lr = 0.01\n",
    "I0930 23:31:51.672552 14384 solver.cpp:228] Iteration 2580, loss = 0.0652697\n",
    "I0930 23:31:51.672552 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0652699 (* 1 = 0.0652699 loss)\n",
    "I0930 23:31:51.672552 14384 sgd_solver.cpp:106] Iteration 2580, lr = 0.01\n",
    "I0930 23:31:51.806148 14384 solver.cpp:228] Iteration 2600, loss = 0.0385703\n",
    "I0930 23:31:51.806148 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0385705 (* 1 = 0.0385705 loss)\n",
    "I0930 23:31:51.806148 14384 sgd_solver.cpp:106] Iteration 2600, lr = 0.01\n",
    "I0930 23:31:51.939741 14384 solver.cpp:228] Iteration 2620, loss = 0.0152882\n",
    "I0930 23:31:51.939741 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0152883 (* 1 = 0.0152883 loss)\n",
    "I0930 23:31:51.939741 14384 sgd_solver.cpp:106] Iteration 2620, lr = 0.01\n",
    "I0930 23:31:52.070833 14384 solver.cpp:228] Iteration 2640, loss = 0.0467948\n",
    "I0930 23:31:52.070833 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.046795 (* 1 = 0.046795 loss)\n",
    "I0930 23:31:52.070833 14384 sgd_solver.cpp:106] Iteration 2640, lr = 0.01\n",
    "I0930 23:31:52.205430 14384 solver.cpp:228] Iteration 2660, loss = 0.0167709\n",
    "I0930 23:31:52.205430 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0167711 (* 1 = 0.0167711 loss)\n",
    "I0930 23:31:52.211433 14384 sgd_solver.cpp:106] Iteration 2660, lr = 0.01\n",
    "I0930 23:31:52.348531 14384 solver.cpp:228] Iteration 2680, loss = 0.0118788\n",
    "I0930 23:31:52.349031 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0118789 (* 1 = 0.0118789 loss)\n",
    "I0930 23:31:52.349031 14384 sgd_solver.cpp:106] Iteration 2680, lr = 0.01\n",
    "I0930 23:31:52.499636 14384 solver.cpp:228] Iteration 2700, loss = 0.0709573\n",
    "I0930 23:31:52.499636 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0709574 (* 1 = 0.0709574 loss)\n",
    "I0930 23:31:52.499636 14384 sgd_solver.cpp:106] Iteration 2700, lr = 0.01\n",
    "I0930 23:31:52.642737 14384 solver.cpp:228] Iteration 2720, loss = 0.0443119\n",
    "I0930 23:31:52.642737 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.044312 (* 1 = 0.044312 loss)\n",
    "I0930 23:31:52.642737 14384 sgd_solver.cpp:106] Iteration 2720, lr = 0.01\n",
    "I0930 23:31:52.790841 14384 solver.cpp:228] Iteration 2740, loss = 0.00791547\n",
    "I0930 23:31:52.790841 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00791563 (* 1 = 0.00791563 loss)\n",
    "I0930 23:31:52.790841 14384 sgd_solver.cpp:106] Iteration 2740, lr = 0.01\n",
    "I0930 23:31:52.946952 14384 solver.cpp:228] Iteration 2760, loss = 0.0125709\n",
    "I0930 23:31:52.946952 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0125711 (* 1 = 0.0125711 loss)\n",
    "I0930 23:31:52.946952 14384 sgd_solver.cpp:106] Iteration 2760, lr = 0.01\n",
    "I0930 23:31:53.105564 14384 solver.cpp:228] Iteration 2780, loss = 0.0133279\n",
    "I0930 23:31:53.105564 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.013328 (* 1 = 0.013328 loss)\n",
    "I0930 23:31:53.105564 14384 sgd_solver.cpp:106] Iteration 2780, lr = 0.01\n",
    "I0930 23:31:53.253168 14384 solver.cpp:228] Iteration 2800, loss = 0.000945962\n",
    "I0930 23:31:53.253168 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000946118 (* 1 = 0.000946118 loss)\n",
    "I0930 23:31:53.253168 14384 sgd_solver.cpp:106] Iteration 2800, lr = 0.01\n",
    "I0930 23:31:53.351738 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_2814.caffemodel\n",
    "I0930 23:31:53.370751 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_2814.solverstate\n",
    "I0930 23:31:53.377256 14384 solver.cpp:337] Iteration 2814, Testing net (#0)\n",
    "I0930 23:31:58.880638 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9846\n",
    "I0930 23:31:58.880638 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0449255 (* 1 = 0.0449255 loss)\n",
    "I0930 23:31:58.929173 14384 solver.cpp:228] Iteration 2820, loss = 0.163876\n",
    "I0930 23:31:58.929173 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.163876 (* 1 = 0.163876 loss)\n",
    "I0930 23:31:58.929173 14384 sgd_solver.cpp:106] Iteration 2820, lr = 0.01\n",
    "I0930 23:31:59.081781 14384 solver.cpp:228] Iteration 2840, loss = 0.0022964\n",
    "I0930 23:31:59.081781 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00229659 (* 1 = 0.00229659 loss)\n",
    "I0930 23:31:59.081781 14384 sgd_solver.cpp:106] Iteration 2840, lr = 0.01\n",
    "I0930 23:31:59.232388 14384 solver.cpp:228] Iteration 2860, loss = 0.0030819\n",
    "I0930 23:31:59.232388 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00308208 (* 1 = 0.00308208 loss)\n",
    "I0930 23:31:59.232388 14384 sgd_solver.cpp:106] Iteration 2860, lr = 0.01\n",
    "I0930 23:31:59.444036 14384 solver.cpp:228] Iteration 2880, loss = 0.0953084\n",
    "I0930 23:31:59.444036 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0953086 (* 1 = 0.0953086 loss)\n",
    "I0930 23:31:59.444036 14384 sgd_solver.cpp:106] Iteration 2880, lr = 0.01\n",
    "I0930 23:31:59.654184 14384 solver.cpp:228] Iteration 2900, loss = 0.0118392\n",
    "I0930 23:31:59.654184 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0118394 (* 1 = 0.0118394 loss)\n",
    "I0930 23:31:59.654184 14384 sgd_solver.cpp:106] Iteration 2900, lr = 0.01\n",
    "I0930 23:31:59.843318 14384 solver.cpp:228] Iteration 2920, loss = 0.0277607\n",
    "I0930 23:31:59.843318 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0277608 (* 1 = 0.0277608 loss)\n",
    "I0930 23:31:59.846820 14384 sgd_solver.cpp:106] Iteration 2920, lr = 0.01\n",
    "I0930 23:32:00.236095 14384 solver.cpp:228] Iteration 2940, loss = 0.0900726\n",
    "I0930 23:32:00.236095 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0900728 (* 1 = 0.0900728 loss)\n",
    "I0930 23:32:00.236095 14384 sgd_solver.cpp:106] Iteration 2940, lr = 0.01\n",
    "I0930 23:32:00.383199 14384 solver.cpp:228] Iteration 2960, loss = 0.0475543\n",
    "I0930 23:32:00.383199 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0475545 (* 1 = 0.0475545 loss)\n",
    "I0930 23:32:00.383199 14384 sgd_solver.cpp:106] Iteration 2960, lr = 0.01\n",
    "I0930 23:32:00.539309 14384 solver.cpp:228] Iteration 2980, loss = 0.0228713\n",
    "I0930 23:32:00.539309 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0228715 (* 1 = 0.0228715 loss)\n",
    "I0930 23:32:00.539309 14384 sgd_solver.cpp:106] Iteration 2980, lr = 0.01\n",
    "I0930 23:32:00.710430 14384 solver.cpp:228] Iteration 3000, loss = 0.00732483\n",
    "I0930 23:32:00.710930 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00732499 (* 1 = 0.00732499 loss)\n",
    "I0930 23:32:00.710930 14384 sgd_solver.cpp:106] Iteration 3000, lr = 0.001\n",
    "I0930 23:32:00.849028 14384 solver.cpp:228] Iteration 3020, loss = 0.0178656\n",
    "I0930 23:32:00.849028 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0178658 (* 1 = 0.0178658 loss)\n",
    "I0930 23:32:00.849028 14384 sgd_solver.cpp:106] Iteration 3020, lr = 0.001\n",
    "I0930 23:32:01.011142 14384 solver.cpp:228] Iteration 3040, loss = 0.0332389\n",
    "I0930 23:32:01.011642 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.033239 (* 1 = 0.033239 loss)\n",
    "I0930 23:32:01.011642 14384 sgd_solver.cpp:106] Iteration 3040, lr = 0.001\n",
    "I0930 23:32:01.067181 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:32:01.177760 14384 solver.cpp:228] Iteration 3060, loss = 0.014225\n",
    "I0930 23:32:01.177760 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0142251 (* 1 = 0.0142251 loss)\n",
    "I0930 23:32:01.178261 14384 sgd_solver.cpp:106] Iteration 3060, lr = 0.001\n",
    "I0930 23:32:01.333870 14384 solver.cpp:228] Iteration 3080, loss = 0.00931336\n",
    "I0930 23:32:01.333870 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00931353 (* 1 = 0.00931353 loss)\n",
    "I0930 23:32:01.333870 14384 sgd_solver.cpp:106] Iteration 3080, lr = 0.001\n",
    "I0930 23:32:01.501488 14384 solver.cpp:228] Iteration 3100, loss = 0.00821767\n",
    "I0930 23:32:01.501488 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00821784 (* 1 = 0.00821784 loss)\n",
    "I0930 23:32:01.501488 14384 sgd_solver.cpp:106] Iteration 3100, lr = 0.001\n",
    "I0930 23:32:01.661101 14384 solver.cpp:228] Iteration 3120, loss = 0.00901223\n",
    "I0930 23:32:01.661101 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0090124 (* 1 = 0.0090124 loss)\n",
    "I0930 23:32:01.661101 14384 sgd_solver.cpp:106] Iteration 3120, lr = 0.001\n",
    "I0930 23:32:01.805702 14384 solver.cpp:228] Iteration 3140, loss = 0.0179668\n",
    "I0930 23:32:01.805702 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.017967 (* 1 = 0.017967 loss)\n",
    "I0930 23:32:01.805702 14384 sgd_solver.cpp:106] Iteration 3140, lr = 0.001\n",
    "I0930 23:32:01.949304 14384 solver.cpp:228] Iteration 3160, loss = 0.015131\n",
    "I0930 23:32:01.949304 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0151312 (* 1 = 0.0151312 loss)\n",
    "I0930 23:32:01.949304 14384 sgd_solver.cpp:106] Iteration 3160, lr = 0.001\n",
    "I0930 23:32:02.097908 14384 solver.cpp:228] Iteration 3180, loss = 0.0170185\n",
    "I0930 23:32:02.098409 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0170187 (* 1 = 0.0170187 loss)\n",
    "I0930 23:32:02.098409 14384 sgd_solver.cpp:106] Iteration 3180, lr = 0.001\n",
    "I0930 23:32:02.240509 14384 solver.cpp:228] Iteration 3200, loss = 0.0145687\n",
    "I0930 23:32:02.240509 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0145689 (* 1 = 0.0145689 loss)\n",
    "I0930 23:32:02.240509 14384 sgd_solver.cpp:106] Iteration 3200, lr = 0.001\n",
    "I0930 23:32:02.389614 14384 solver.cpp:228] Iteration 3220, loss = 0.00416537\n",
    "I0930 23:32:02.391615 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00416554 (* 1 = 0.00416554 loss)\n",
    "I0930 23:32:02.391615 14384 sgd_solver.cpp:106] Iteration 3220, lr = 0.001\n",
    "I0930 23:32:02.556732 14384 solver.cpp:228] Iteration 3240, loss = 0.00450161\n",
    "I0930 23:32:02.556732 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00450178 (* 1 = 0.00450178 loss)\n",
    "I0930 23:32:02.556732 14384 sgd_solver.cpp:106] Iteration 3240, lr = 0.001\n",
    "I0930 23:32:02.714344 14384 solver.cpp:228] Iteration 3260, loss = 0.0638891\n",
    "I0930 23:32:02.714344 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0638893 (* 1 = 0.0638893 loss)\n",
    "I0930 23:32:02.714344 14384 sgd_solver.cpp:106] Iteration 3260, lr = 0.001\n",
    "I0930 23:32:02.850440 14384 solver.cpp:228] Iteration 3280, loss = 0.0177919\n",
    "I0930 23:32:02.850440 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.017792 (* 1 = 0.017792 loss)\n",
    "I0930 23:32:02.850440 14384 sgd_solver.cpp:106] Iteration 3280, lr = 0.001\n",
    "I0930 23:32:03.000046 14384 solver.cpp:228] Iteration 3300, loss = 0.00619466\n",
    "I0930 23:32:03.000046 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00619483 (* 1 = 0.00619483 loss)\n",
    "I0930 23:32:03.000046 14384 sgd_solver.cpp:106] Iteration 3300, lr = 0.001\n",
    "I0930 23:32:03.139643 14384 solver.cpp:228] Iteration 3320, loss = 0.00378479\n",
    "I0930 23:32:03.139643 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00378496 (* 1 = 0.00378496 loss)\n",
    "I0930 23:32:03.139643 14384 sgd_solver.cpp:106] Iteration 3320, lr = 0.001\n",
    "I0930 23:32:03.285246 14384 solver.cpp:228] Iteration 3340, loss = 0.0550431\n",
    "I0930 23:32:03.285246 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0550433 (* 1 = 0.0550433 loss)\n",
    "I0930 23:32:03.285246 14384 sgd_solver.cpp:106] Iteration 3340, lr = 0.001\n",
    "I0930 23:32:03.432852 14384 solver.cpp:228] Iteration 3360, loss = 0.0134787\n",
    "I0930 23:32:03.432852 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0134789 (* 1 = 0.0134789 loss)\n",
    "I0930 23:32:03.433351 14384 sgd_solver.cpp:106] Iteration 3360, lr = 0.001\n",
    "I0930 23:32:03.574451 14384 solver.cpp:228] Iteration 3380, loss = 0.00941305\n",
    "I0930 23:32:03.574451 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00941322 (* 1 = 0.00941322 loss)\n",
    "I0930 23:32:03.574451 14384 sgd_solver.cpp:106] Iteration 3380, lr = 0.001\n",
    "I0930 23:32:03.722555 14384 solver.cpp:228] Iteration 3400, loss = 0.00329397\n",
    "I0930 23:32:03.722555 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00329414 (* 1 = 0.00329414 loss)\n",
    "I0930 23:32:03.722555 14384 sgd_solver.cpp:106] Iteration 3400, lr = 0.001\n",
    "I0930 23:32:03.878665 14384 solver.cpp:228] Iteration 3420, loss = 0.0267844\n",
    "I0930 23:32:03.878665 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0267845 (* 1 = 0.0267845 loss)\n",
    "I0930 23:32:03.878665 14384 sgd_solver.cpp:106] Iteration 3420, lr = 0.001\n",
    "I0930 23:32:04.068298 14384 solver.cpp:228] Iteration 3440, loss = 0.000762716\n",
    "I0930 23:32:04.068298 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000762869 (* 1 = 0.000762869 loss)\n",
    "I0930 23:32:04.068298 14384 sgd_solver.cpp:106] Iteration 3440, lr = 0.001\n",
    "I0930 23:32:04.237419 14384 solver.cpp:228] Iteration 3460, loss = 0.0156569\n",
    "I0930 23:32:04.237419 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.015657 (* 1 = 0.015657 loss)\n",
    "I0930 23:32:04.237419 14384 sgd_solver.cpp:106] Iteration 3460, lr = 0.001\n",
    "I0930 23:32:04.372014 14384 solver.cpp:228] Iteration 3480, loss = 0.00754318\n",
    "I0930 23:32:04.372014 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00754333 (* 1 = 0.00754333 loss)\n",
    "I0930 23:32:04.372014 14384 sgd_solver.cpp:106] Iteration 3480, lr = 0.001\n",
    "I0930 23:32:04.516115 14384 solver.cpp:228] Iteration 3500, loss = 0.00143633\n",
    "I0930 23:32:04.516115 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00143648 (* 1 = 0.00143648 loss)\n",
    "I0930 23:32:04.516115 14384 sgd_solver.cpp:106] Iteration 3500, lr = 0.001\n",
    "I0930 23:32:04.678730 14384 solver.cpp:228] Iteration 3520, loss = 0.00030359\n",
    "I0930 23:32:04.682232 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000303738 (* 1 = 0.000303738 loss)\n",
    "I0930 23:32:04.682232 14384 sgd_solver.cpp:106] Iteration 3520, lr = 0.001\n",
    "I0930 23:32:04.834841 14384 solver.cpp:228] Iteration 3540, loss = 0.000955424\n",
    "I0930 23:32:04.834841 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000955574 (* 1 = 0.000955574 loss)\n",
    "I0930 23:32:04.834841 14384 sgd_solver.cpp:106] Iteration 3540, lr = 0.001\n",
    "I0930 23:32:04.996454 14384 solver.cpp:228] Iteration 3560, loss = 0.0150212\n",
    "I0930 23:32:04.996454 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0150213 (* 1 = 0.0150213 loss)\n",
    "I0930 23:32:04.996454 14384 sgd_solver.cpp:106] Iteration 3560, lr = 0.001\n",
    "I0930 23:32:05.158068 14384 solver.cpp:228] Iteration 3580, loss = 0.0272456\n",
    "I0930 23:32:05.158068 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0272457 (* 1 = 0.0272457 loss)\n",
    "I0930 23:32:05.158068 14384 sgd_solver.cpp:106] Iteration 3580, lr = 0.001\n",
    "I0930 23:32:05.311676 14384 solver.cpp:228] Iteration 3600, loss = 0.0187643\n",
    "I0930 23:32:05.311676 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0187644 (* 1 = 0.0187644 loss)\n",
    "I0930 23:32:05.311676 14384 sgd_solver.cpp:106] Iteration 3600, lr = 0.001\n",
    "I0930 23:32:05.475291 14384 solver.cpp:228] Iteration 3620, loss = 0.00419303\n",
    "I0930 23:32:05.475291 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00419317 (* 1 = 0.00419317 loss)\n",
    "I0930 23:32:05.475291 14384 sgd_solver.cpp:106] Iteration 3620, lr = 0.001\n",
    "I0930 23:32:05.625898 14384 solver.cpp:228] Iteration 3640, loss = 0.0308876\n",
    "I0930 23:32:05.625898 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0308877 (* 1 = 0.0308877 loss)\n",
    "I0930 23:32:05.625898 14384 sgd_solver.cpp:106] Iteration 3640, lr = 0.001\n",
    "I0930 23:32:05.756991 14384 solver.cpp:228] Iteration 3660, loss = 0.0300004\n",
    "I0930 23:32:05.756991 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0300006 (* 1 = 0.0300006 loss)\n",
    "I0930 23:32:05.756991 14384 sgd_solver.cpp:106] Iteration 3660, lr = 0.001\n",
    "I0930 23:32:05.890584 14384 solver.cpp:228] Iteration 3680, loss = 0.000776292\n",
    "I0930 23:32:05.890584 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000776443 (* 1 = 0.000776443 loss)\n",
    "I0930 23:32:05.890584 14384 sgd_solver.cpp:106] Iteration 3680, lr = 0.001\n",
    "I0930 23:32:06.037189 14384 solver.cpp:228] Iteration 3700, loss = 0.0257608\n",
    "I0930 23:32:06.037189 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0257609 (* 1 = 0.0257609 loss)\n",
    "I0930 23:32:06.037189 14384 sgd_solver.cpp:106] Iteration 3700, lr = 0.001\n",
    "I0930 23:32:06.181790 14384 solver.cpp:228] Iteration 3720, loss = 0.00286774\n",
    "I0930 23:32:06.181790 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00286789 (* 1 = 0.00286789 loss)\n",
    "I0930 23:32:06.181790 14384 sgd_solver.cpp:106] Iteration 3720, lr = 0.001\n",
    "I0930 23:32:06.328393 14384 solver.cpp:228] Iteration 3740, loss = 0.00375702\n",
    "I0930 23:32:06.328393 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00375717 (* 1 = 0.00375717 loss)\n",
    "I0930 23:32:06.328393 14384 sgd_solver.cpp:106] Iteration 3740, lr = 0.001\n",
    "I0930 23:32:06.406949 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_3752.caffemodel\n",
    "I0930 23:32:06.422461 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_3752.solverstate\n",
    "I0930 23:32:06.428966 14384 solver.cpp:337] Iteration 3752, Testing net (#0)\n",
    "I0930 23:32:09.600203 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:32:12.189029 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9912\n",
    "I0930 23:32:12.189029 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0297845 (* 1 = 0.0297845 loss)\n",
    "I0930 23:32:12.250072 14384 solver.cpp:228] Iteration 3760, loss = 0.00460489\n",
    "I0930 23:32:12.250072 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00460503 (* 1 = 0.00460503 loss)\n",
    "I0930 23:32:12.255075 14384 sgd_solver.cpp:106] Iteration 3760, lr = 0.001\n",
    "I0930 23:32:12.415189 14384 solver.cpp:228] Iteration 3780, loss = 0.0133124\n",
    "I0930 23:32:12.415189 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0133126 (* 1 = 0.0133126 loss)\n",
    "I0930 23:32:12.415189 14384 sgd_solver.cpp:106] Iteration 3780, lr = 0.001\n",
    "I0930 23:32:12.621335 14384 solver.cpp:228] Iteration 3800, loss = 0.00284156\n",
    "I0930 23:32:12.621335 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0028417 (* 1 = 0.0028417 loss)\n",
    "I0930 23:32:12.621335 14384 sgd_solver.cpp:106] Iteration 3800, lr = 0.001\n",
    "I0930 23:32:12.822475 14384 solver.cpp:228] Iteration 3820, loss = 0.00140567\n",
    "I0930 23:32:12.822475 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00140583 (* 1 = 0.00140583 loss)\n",
    "I0930 23:32:12.822475 14384 sgd_solver.cpp:106] Iteration 3820, lr = 0.001\n",
    "I0930 23:32:12.961575 14384 solver.cpp:228] Iteration 3840, loss = 0.00816039\n",
    "I0930 23:32:12.961575 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00816054 (* 1 = 0.00816054 loss)\n",
    "I0930 23:32:12.961575 14384 sgd_solver.cpp:106] Iteration 3840, lr = 0.001\n",
    "I0930 23:32:13.110178 14384 solver.cpp:228] Iteration 3860, loss = 0.046532\n",
    "I0930 23:32:13.110178 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0465322 (* 1 = 0.0465322 loss)\n",
    "I0930 23:32:13.110178 14384 sgd_solver.cpp:106] Iteration 3860, lr = 0.001\n",
    "I0930 23:32:13.373364 14384 solver.cpp:228] Iteration 3880, loss = 0.00106951\n",
    "I0930 23:32:13.373364 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00106966 (* 1 = 0.00106966 loss)\n",
    "I0930 23:32:13.373364 14384 sgd_solver.cpp:106] Iteration 3880, lr = 0.001\n",
    "I0930 23:32:13.573005 14384 solver.cpp:228] Iteration 3900, loss = 0.00417153\n",
    "I0930 23:32:13.573005 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00417169 (* 1 = 0.00417169 loss)\n",
    "I0930 23:32:13.573005 14384 sgd_solver.cpp:106] Iteration 3900, lr = 0.001\n",
    "I0930 23:32:13.844697 14384 solver.cpp:228] Iteration 3920, loss = 0.00508736\n",
    "I0930 23:32:13.844697 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00508751 (* 1 = 0.00508751 loss)\n",
    "I0930 23:32:13.844697 14384 sgd_solver.cpp:106] Iteration 3920, lr = 0.001\n",
    "I0930 23:32:14.057348 14384 solver.cpp:228] Iteration 3940, loss = 0.0262139\n",
    "I0930 23:32:14.057348 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0262141 (* 1 = 0.0262141 loss)\n",
    "I0930 23:32:14.057348 14384 sgd_solver.cpp:106] Iteration 3940, lr = 0.001\n",
    "I0930 23:32:14.305022 14384 solver.cpp:228] Iteration 3960, loss = 0.00746614\n",
    "I0930 23:32:14.305022 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0074663 (* 1 = 0.0074663 loss)\n",
    "I0930 23:32:14.305022 14384 sgd_solver.cpp:106] Iteration 3960, lr = 0.001\n",
    "I0930 23:32:14.483647 14384 solver.cpp:228] Iteration 3980, loss = 0.0204641\n",
    "I0930 23:32:14.484148 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0204643 (* 1 = 0.0204643 loss)\n",
    "I0930 23:32:14.484148 14384 sgd_solver.cpp:106] Iteration 3980, lr = 0.001\n",
    "I0930 23:32:14.631752 14384 solver.cpp:228] Iteration 4000, loss = 0.00799995\n",
    "I0930 23:32:14.631752 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0080001 (* 1 = 0.0080001 loss)\n",
    "I0930 23:32:14.631752 14384 sgd_solver.cpp:106] Iteration 4000, lr = 0.001\n",
    "I0930 23:32:14.848911 14384 solver.cpp:228] Iteration 4020, loss = 0.000586142\n",
    "I0930 23:32:14.848911 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0005863 (* 1 = 0.0005863 loss)\n",
    "I0930 23:32:14.848911 14384 sgd_solver.cpp:106] Iteration 4020, lr = 0.001\n",
    "I0930 23:32:15.104586 14384 solver.cpp:228] Iteration 4040, loss = 0.00562904\n",
    "I0930 23:32:15.104586 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00562919 (* 1 = 0.00562919 loss)\n",
    "I0930 23:32:15.104586 14384 sgd_solver.cpp:106] Iteration 4040, lr = 0.001\n",
    "I0930 23:32:15.288215 14384 solver.cpp:228] Iteration 4060, loss = 0.0159599\n",
    "I0930 23:32:15.288215 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0159601 (* 1 = 0.0159601 loss)\n",
    "I0930 23:32:15.290217 14384 sgd_solver.cpp:106] Iteration 4060, lr = 0.001\n",
    "I0930 23:32:15.457334 14384 solver.cpp:228] Iteration 4080, loss = 0.0204419\n",
    "I0930 23:32:15.457334 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0204421 (* 1 = 0.0204421 loss)\n",
    "I0930 23:32:15.457334 14384 sgd_solver.cpp:106] Iteration 4080, lr = 0.001\n",
    "I0930 23:32:15.635462 14384 solver.cpp:228] Iteration 4100, loss = 0.0286903\n",
    "I0930 23:32:15.635462 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0286905 (* 1 = 0.0286905 loss)\n",
    "I0930 23:32:15.635462 14384 sgd_solver.cpp:106] Iteration 4100, lr = 0.001\n",
    "I0930 23:32:15.781064 14384 solver.cpp:228] Iteration 4120, loss = 0.0198472\n",
    "I0930 23:32:15.781064 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0198474 (* 1 = 0.0198474 loss)\n",
    "I0930 23:32:15.781064 14384 sgd_solver.cpp:106] Iteration 4120, lr = 0.001\n",
    "I0930 23:32:15.973701 14384 solver.cpp:228] Iteration 4140, loss = 0.000733171\n",
    "I0930 23:32:15.973701 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00073333 (* 1 = 0.00073333 loss)\n",
    "I0930 23:32:15.973701 14384 sgd_solver.cpp:106] Iteration 4140, lr = 0.001\n",
    "I0930 23:32:16.227378 14384 solver.cpp:228] Iteration 4160, loss = 0.00175145\n",
    "I0930 23:32:16.227378 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00175162 (* 1 = 0.00175162 loss)\n",
    "I0930 23:32:16.227378 14384 sgd_solver.cpp:106] Iteration 4160, lr = 0.001\n",
    "I0930 23:32:16.365977 14384 solver.cpp:228] Iteration 4180, loss = 0.0172892\n",
    "I0930 23:32:16.365977 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0172894 (* 1 = 0.0172894 loss)\n",
    "I0930 23:32:16.365977 14384 sgd_solver.cpp:106] Iteration 4180, lr = 0.001\n",
    "I0930 23:32:16.642671 14384 solver.cpp:228] Iteration 4200, loss = 0.00339582\n",
    "I0930 23:32:16.642671 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00339598 (* 1 = 0.00339598 loss)\n",
    "I0930 23:32:16.642671 14384 sgd_solver.cpp:106] Iteration 4200, lr = 0.001\n",
    "I0930 23:32:16.811791 14384 solver.cpp:228] Iteration 4220, loss = 0.0137967\n",
    "I0930 23:32:16.811791 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0137968 (* 1 = 0.0137968 loss)\n",
    "I0930 23:32:16.811791 14384 sgd_solver.cpp:106] Iteration 4220, lr = 0.001\n",
    "I0930 23:32:16.951390 14384 solver.cpp:228] Iteration 4240, loss = 0.00844053\n",
    "I0930 23:32:16.951390 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00844069 (* 1 = 0.00844069 loss)\n",
    "I0930 23:32:16.951390 14384 sgd_solver.cpp:106] Iteration 4240, lr = 0.001\n",
    "I0930 23:32:17.096992 14384 solver.cpp:228] Iteration 4260, loss = 0.0036192\n",
    "I0930 23:32:17.096992 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00361936 (* 1 = 0.00361936 loss)\n",
    "I0930 23:32:17.096992 14384 sgd_solver.cpp:106] Iteration 4260, lr = 0.001\n",
    "I0930 23:32:17.237591 14384 solver.cpp:228] Iteration 4280, loss = 0.00161241\n",
    "I0930 23:32:17.237591 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00161258 (* 1 = 0.00161258 loss)\n",
    "I0930 23:32:17.237591 14384 sgd_solver.cpp:106] Iteration 4280, lr = 0.001\n",
    "I0930 23:32:17.398205 14384 solver.cpp:228] Iteration 4300, loss = 0.0677031\n",
    "I0930 23:32:17.398205 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0677033 (* 1 = 0.0677033 loss)\n",
    "I0930 23:32:17.398205 14384 sgd_solver.cpp:106] Iteration 4300, lr = 0.001\n",
    "I0930 23:32:17.554314 14384 solver.cpp:228] Iteration 4320, loss = 0.00150361\n",
    "I0930 23:32:17.554314 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00150375 (* 1 = 0.00150375 loss)\n",
    "I0930 23:32:17.554314 14384 sgd_solver.cpp:106] Iteration 4320, lr = 0.001\n",
    "I0930 23:32:17.693913 14384 solver.cpp:228] Iteration 4340, loss = 0.0231638\n",
    "I0930 23:32:17.693913 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0231639 (* 1 = 0.0231639 loss)\n",
    "I0930 23:32:17.693913 14384 sgd_solver.cpp:106] Iteration 4340, lr = 0.001\n",
    "I0930 23:32:17.835513 14384 solver.cpp:228] Iteration 4360, loss = 0.000392101\n",
    "I0930 23:32:17.835513 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000392253 (* 1 = 0.000392253 loss)\n",
    "I0930 23:32:17.839515 14384 sgd_solver.cpp:106] Iteration 4360, lr = 0.001\n",
    "I0930 23:32:18.008136 14384 solver.cpp:228] Iteration 4380, loss = 0.0025821\n",
    "I0930 23:32:18.008136 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00258227 (* 1 = 0.00258227 loss)\n",
    "I0930 23:32:18.008136 14384 sgd_solver.cpp:106] Iteration 4380, lr = 0.001\n",
    "I0930 23:32:18.252807 14384 solver.cpp:228] Iteration 4400, loss = 0.00665246\n",
    "I0930 23:32:18.252807 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00665262 (* 1 = 0.00665262 loss)\n",
    "I0930 23:32:18.252807 14384 sgd_solver.cpp:106] Iteration 4400, lr = 0.001\n",
    "I0930 23:32:18.434437 14384 solver.cpp:228] Iteration 4420, loss = 0.00701427\n",
    "I0930 23:32:18.434437 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00701443 (* 1 = 0.00701443 loss)\n",
    "I0930 23:32:18.434437 14384 sgd_solver.cpp:106] Iteration 4420, lr = 0.001\n",
    "I0930 23:32:18.584542 14384 solver.cpp:228] Iteration 4440, loss = 0.00462777\n",
    "I0930 23:32:18.584542 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00462793 (* 1 = 0.00462793 loss)\n",
    "I0930 23:32:18.584542 14384 sgd_solver.cpp:106] Iteration 4440, lr = 0.001\n",
    "I0930 23:32:18.785683 14384 solver.cpp:228] Iteration 4460, loss = 0.0254683\n",
    "I0930 23:32:18.785683 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0254685 (* 1 = 0.0254685 loss)\n",
    "I0930 23:32:18.785683 14384 sgd_solver.cpp:106] Iteration 4460, lr = 0.001\n",
    "I0930 23:32:19.053371 14384 solver.cpp:228] Iteration 4480, loss = 0.0311735\n",
    "I0930 23:32:19.053371 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0311737 (* 1 = 0.0311737 loss)\n",
    "I0930 23:32:19.053371 14384 sgd_solver.cpp:106] Iteration 4480, lr = 0.001\n",
    "I0930 23:32:19.196475 14384 solver.cpp:228] Iteration 4500, loss = 0.00747525\n",
    "I0930 23:32:19.196475 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00747542 (* 1 = 0.00747542 loss)\n",
    "I0930 23:32:19.196475 14384 sgd_solver.cpp:106] Iteration 4500, lr = 0.001\n",
    "I0930 23:32:19.332569 14384 solver.cpp:228] Iteration 4520, loss = 0.00163584\n",
    "I0930 23:32:19.332569 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00163602 (* 1 = 0.00163602 loss)\n",
    "I0930 23:32:19.332569 14384 sgd_solver.cpp:106] Iteration 4520, lr = 0.001\n",
    "I0930 23:32:19.490680 14384 solver.cpp:228] Iteration 4540, loss = 0.00587203\n",
    "I0930 23:32:19.490680 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00587221 (* 1 = 0.00587221 loss)\n",
    "I0930 23:32:19.490680 14384 sgd_solver.cpp:106] Iteration 4540, lr = 0.001\n",
    "I0930 23:32:19.731354 14384 solver.cpp:228] Iteration 4560, loss = 0.0101309\n",
    "I0930 23:32:19.731354 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0101311 (* 1 = 0.0101311 loss)\n",
    "I0930 23:32:19.731354 14384 sgd_solver.cpp:106] Iteration 4560, lr = 0.001\n",
    "I0930 23:32:19.752365 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:32:19.926988 14384 solver.cpp:228] Iteration 4580, loss = 0.00634645\n",
    "I0930 23:32:19.926988 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00634662 (* 1 = 0.00634662 loss)\n",
    "I0930 23:32:19.926988 14384 sgd_solver.cpp:106] Iteration 4580, lr = 0.001\n",
    "I0930 23:32:20.070089 14384 solver.cpp:228] Iteration 4600, loss = 0.0255573\n",
    "I0930 23:32:20.070089 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0255575 (* 1 = 0.0255575 loss)\n",
    "I0930 23:32:20.070089 14384 sgd_solver.cpp:106] Iteration 4600, lr = 0.001\n",
    "I0930 23:32:20.232204 14384 solver.cpp:228] Iteration 4620, loss = 0.01157\n",
    "I0930 23:32:20.232204 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0115702 (* 1 = 0.0115702 loss)\n",
    "I0930 23:32:20.232204 14384 sgd_solver.cpp:106] Iteration 4620, lr = 0.001\n",
    "I0930 23:32:20.392817 14384 solver.cpp:228] Iteration 4640, loss = 0.00534184\n",
    "I0930 23:32:20.392817 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00534202 (* 1 = 0.00534202 loss)\n",
    "I0930 23:32:20.392817 14384 sgd_solver.cpp:106] Iteration 4640, lr = 0.001\n",
    "I0930 23:32:20.557934 14384 solver.cpp:228] Iteration 4660, loss = 0.00134809\n",
    "I0930 23:32:20.561439 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00134827 (* 1 = 0.00134827 loss)\n",
    "I0930 23:32:20.561439 14384 sgd_solver.cpp:106] Iteration 4660, lr = 0.001\n",
    "I0930 23:32:20.722550 14384 solver.cpp:228] Iteration 4680, loss = 0.000544961\n",
    "I0930 23:32:20.722550 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000545134 (* 1 = 0.000545134 loss)\n",
    "I0930 23:32:20.722550 14384 sgd_solver.cpp:106] Iteration 4680, lr = 0.001\n",
    "I0930 23:32:20.797103 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_4690.caffemodel\n",
    "I0930 23:32:20.816617 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_4690.solverstate\n",
    "I0930 23:32:20.822621 14384 solver.cpp:337] Iteration 4690, Testing net (#0)\n",
    "I0930 23:32:26.690762 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9914\n",
    "I0930 23:32:26.690762 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0283933 (* 1 = 0.0283933 loss)\n",
    "I0930 23:32:26.773820 14384 solver.cpp:228] Iteration 4700, loss = 0.00316571\n",
    "I0930 23:32:26.774320 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00316587 (* 1 = 0.00316587 loss)\n",
    "I0930 23:32:26.774320 14384 sgd_solver.cpp:106] Iteration 4700, lr = 0.001\n",
    "I0930 23:32:26.949944 14384 solver.cpp:228] Iteration 4720, loss = 0.00111581\n",
    "I0930 23:32:26.949944 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00111597 (* 1 = 0.00111597 loss)\n",
    "I0930 23:32:26.949944 14384 sgd_solver.cpp:106] Iteration 4720, lr = 0.001\n",
    "I0930 23:32:27.174101 14384 solver.cpp:228] Iteration 4740, loss = 0.00119566\n",
    "I0930 23:32:27.174101 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00119582 (* 1 = 0.00119582 loss)\n",
    "I0930 23:32:27.174101 14384 sgd_solver.cpp:106] Iteration 4740, lr = 0.001\n",
    "I0930 23:32:27.369740 14384 solver.cpp:228] Iteration 4760, loss = 0.00256569\n",
    "I0930 23:32:27.369740 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00256586 (* 1 = 0.00256586 loss)\n",
    "I0930 23:32:27.369740 14384 sgd_solver.cpp:106] Iteration 4760, lr = 0.001\n",
    "I0930 23:32:27.571383 14384 solver.cpp:228] Iteration 4780, loss = 0.00272892\n",
    "I0930 23:32:27.571383 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00272908 (* 1 = 0.00272908 loss)\n",
    "I0930 23:32:27.571383 14384 sgd_solver.cpp:106] Iteration 4780, lr = 0.001\n",
    "I0930 23:32:27.763519 14384 solver.cpp:228] Iteration 4800, loss = 0.00849312\n",
    "I0930 23:32:27.763519 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00849328 (* 1 = 0.00849328 loss)\n",
    "I0930 23:32:27.763519 14384 sgd_solver.cpp:106] Iteration 4800, lr = 0.001\n",
    "I0930 23:32:27.967161 14384 solver.cpp:228] Iteration 4820, loss = 0.013148\n",
    "I0930 23:32:27.967161 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0131482 (* 1 = 0.0131482 loss)\n",
    "I0930 23:32:27.967161 14384 sgd_solver.cpp:106] Iteration 4820, lr = 0.001\n",
    "I0930 23:32:28.178812 14384 solver.cpp:228] Iteration 4840, loss = 0.00474932\n",
    "I0930 23:32:28.178812 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00474948 (* 1 = 0.00474948 loss)\n",
    "I0930 23:32:28.178812 14384 sgd_solver.cpp:106] Iteration 4840, lr = 0.001\n",
    "I0930 23:32:28.347929 14384 solver.cpp:228] Iteration 4860, loss = 0.00220057\n",
    "I0930 23:32:28.347929 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00220073 (* 1 = 0.00220073 loss)\n",
    "I0930 23:32:28.347929 14384 sgd_solver.cpp:106] Iteration 4860, lr = 0.001\n",
    "I0930 23:32:28.499537 14384 solver.cpp:228] Iteration 4880, loss = 0.00485005\n",
    "I0930 23:32:28.499537 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00485021 (* 1 = 0.00485021 loss)\n",
    "I0930 23:32:28.499537 14384 sgd_solver.cpp:106] Iteration 4880, lr = 0.001\n",
    "I0930 23:32:28.682165 14384 solver.cpp:228] Iteration 4900, loss = 0.00410292\n",
    "I0930 23:32:28.682165 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00410308 (* 1 = 0.00410308 loss)\n",
    "I0930 23:32:28.682165 14384 sgd_solver.cpp:106] Iteration 4900, lr = 0.001\n",
    "I0930 23:32:28.830770 14384 solver.cpp:228] Iteration 4920, loss = 0.00141425\n",
    "I0930 23:32:28.830770 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00141441 (* 1 = 0.00141441 loss)\n",
    "I0930 23:32:28.830770 14384 sgd_solver.cpp:106] Iteration 4920, lr = 0.001\n",
    "I0930 23:32:28.992385 14384 solver.cpp:228] Iteration 4940, loss = 0.00306952\n",
    "I0930 23:32:28.992385 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00306968 (* 1 = 0.00306968 loss)\n",
    "I0930 23:32:28.992385 14384 sgd_solver.cpp:106] Iteration 4940, lr = 0.001\n",
    "I0930 23:32:29.155999 14384 solver.cpp:228] Iteration 4960, loss = 0.00325704\n",
    "I0930 23:32:29.155999 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0032572 (* 1 = 0.0032572 loss)\n",
    "I0930 23:32:29.155999 14384 sgd_solver.cpp:106] Iteration 4960, lr = 0.001\n",
    "I0930 23:32:29.315613 14384 solver.cpp:228] Iteration 4980, loss = 0.00232539\n",
    "I0930 23:32:29.315613 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00232555 (* 1 = 0.00232555 loss)\n",
    "I0930 23:32:29.315613 14384 sgd_solver.cpp:106] Iteration 4980, lr = 0.001\n",
    "I0930 23:32:29.488734 14384 solver.cpp:228] Iteration 5000, loss = 0.0141156\n",
    "I0930 23:32:29.488734 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0141157 (* 1 = 0.0141157 loss)\n",
    "I0930 23:32:29.488734 14384 sgd_solver.cpp:106] Iteration 5000, lr = 0.001\n",
    "I0930 23:32:29.653852 14384 solver.cpp:228] Iteration 5020, loss = 0.00150414\n",
    "I0930 23:32:29.653852 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0015043 (* 1 = 0.0015043 loss)\n",
    "I0930 23:32:29.654352 14384 sgd_solver.cpp:106] Iteration 5020, lr = 0.001\n",
    "I0930 23:32:29.830976 14384 solver.cpp:228] Iteration 5040, loss = 0.0230569\n",
    "I0930 23:32:29.830976 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0230571 (* 1 = 0.0230571 loss)\n",
    "I0930 23:32:29.830976 14384 sgd_solver.cpp:106] Iteration 5040, lr = 0.001\n",
    "I0930 23:32:29.980582 14384 solver.cpp:228] Iteration 5060, loss = 0.00875045\n",
    "I0930 23:32:29.980582 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00875062 (* 1 = 0.00875062 loss)\n",
    "I0930 23:32:29.980582 14384 sgd_solver.cpp:106] Iteration 5060, lr = 0.001\n",
    "I0930 23:32:30.094162 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:32:30.113675 14384 solver.cpp:228] Iteration 5080, loss = 0.0329774\n",
    "I0930 23:32:30.113675 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0329775 (* 1 = 0.0329775 loss)\n",
    "I0930 23:32:30.113675 14384 sgd_solver.cpp:106] Iteration 5080, lr = 0.001\n",
    "I0930 23:32:30.250273 14384 solver.cpp:228] Iteration 5100, loss = 0.026737\n",
    "I0930 23:32:30.250273 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0267371 (* 1 = 0.0267371 loss)\n",
    "I0930 23:32:30.250273 14384 sgd_solver.cpp:106] Iteration 5100, lr = 0.001\n",
    "I0930 23:32:30.392374 14384 solver.cpp:228] Iteration 5120, loss = 0.0313904\n",
    "I0930 23:32:30.392374 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0313906 (* 1 = 0.0313906 loss)\n",
    "I0930 23:32:30.392374 14384 sgd_solver.cpp:106] Iteration 5120, lr = 0.001\n",
    "I0930 23:32:30.552986 14384 solver.cpp:228] Iteration 5140, loss = 0.0123169\n",
    "I0930 23:32:30.552986 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.012317 (* 1 = 0.012317 loss)\n",
    "I0930 23:32:30.552986 14384 sgd_solver.cpp:106] Iteration 5140, lr = 0.001\n",
    "I0930 23:32:30.694087 14384 solver.cpp:228] Iteration 5160, loss = 0.00276509\n",
    "I0930 23:32:30.694087 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00276524 (* 1 = 0.00276524 loss)\n",
    "I0930 23:32:30.694087 14384 sgd_solver.cpp:106] Iteration 5160, lr = 0.001\n",
    "I0930 23:32:30.850697 14384 solver.cpp:228] Iteration 5180, loss = 0.0150421\n",
    "I0930 23:32:30.850697 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0150423 (* 1 = 0.0150423 loss)\n",
    "I0930 23:32:30.850697 14384 sgd_solver.cpp:106] Iteration 5180, lr = 0.001\n",
    "I0930 23:32:31.027321 14384 solver.cpp:228] Iteration 5200, loss = 0.0137441\n",
    "I0930 23:32:31.027321 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0137442 (* 1 = 0.0137442 loss)\n",
    "I0930 23:32:31.028321 14384 sgd_solver.cpp:106] Iteration 5200, lr = 0.001\n",
    "I0930 23:32:31.217455 14384 solver.cpp:228] Iteration 5220, loss = 0.00357531\n",
    "I0930 23:32:31.217455 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00357545 (* 1 = 0.00357545 loss)\n",
    "I0930 23:32:31.217455 14384 sgd_solver.cpp:106] Iteration 5220, lr = 0.001\n",
    "I0930 23:32:31.394079 14384 solver.cpp:228] Iteration 5240, loss = 0.0107143\n",
    "I0930 23:32:31.394079 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0107144 (* 1 = 0.0107144 loss)\n",
    "I0930 23:32:31.394079 14384 sgd_solver.cpp:106] Iteration 5240, lr = 0.001\n",
    "I0930 23:32:31.536680 14384 solver.cpp:228] Iteration 5260, loss = 0.0111654\n",
    "I0930 23:32:31.536680 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0111655 (* 1 = 0.0111655 loss)\n",
    "I0930 23:32:31.536680 14384 sgd_solver.cpp:106] Iteration 5260, lr = 0.001\n",
    "I0930 23:32:31.697793 14384 solver.cpp:228] Iteration 5280, loss = 0.00314617\n",
    "I0930 23:32:31.697793 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00314633 (* 1 = 0.00314633 loss)\n",
    "I0930 23:32:31.697793 14384 sgd_solver.cpp:106] Iteration 5280, lr = 0.001\n",
    "I0930 23:32:31.848399 14384 solver.cpp:228] Iteration 5300, loss = 0.00186071\n",
    "I0930 23:32:31.848399 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00186086 (* 1 = 0.00186086 loss)\n",
    "I0930 23:32:31.848399 14384 sgd_solver.cpp:106] Iteration 5300, lr = 0.001\n",
    "I0930 23:32:31.996505 14384 solver.cpp:228] Iteration 5320, loss = 0.00173535\n",
    "I0930 23:32:31.996505 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00173551 (* 1 = 0.00173551 loss)\n",
    "I0930 23:32:31.996505 14384 sgd_solver.cpp:106] Iteration 5320, lr = 0.001\n",
    "I0930 23:32:32.148612 14384 solver.cpp:228] Iteration 5340, loss = 0.00574337\n",
    "I0930 23:32:32.148612 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00574352 (* 1 = 0.00574352 loss)\n",
    "I0930 23:32:32.148612 14384 sgd_solver.cpp:106] Iteration 5340, lr = 0.001\n",
    "I0930 23:32:32.288211 14384 solver.cpp:228] Iteration 5360, loss = 0.00453148\n",
    "I0930 23:32:32.288211 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00453164 (* 1 = 0.00453164 loss)\n",
    "I0930 23:32:32.288211 14384 sgd_solver.cpp:106] Iteration 5360, lr = 0.001\n",
    "I0930 23:32:32.446822 14384 solver.cpp:228] Iteration 5380, loss = 0.0160126\n",
    "I0930 23:32:32.446822 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0160128 (* 1 = 0.0160128 loss)\n",
    "I0930 23:32:32.446822 14384 sgd_solver.cpp:106] Iteration 5380, lr = 0.001\n",
    "I0930 23:32:32.608937 14384 solver.cpp:228] Iteration 5400, loss = 0.00599569\n",
    "I0930 23:32:32.608937 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00599584 (* 1 = 0.00599584 loss)\n",
    "I0930 23:32:32.608937 14384 sgd_solver.cpp:106] Iteration 5400, lr = 0.001\n",
    "I0930 23:32:32.750536 14384 solver.cpp:228] Iteration 5420, loss = 0.0110656\n",
    "I0930 23:32:32.750536 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0110657 (* 1 = 0.0110657 loss)\n",
    "I0930 23:32:32.750536 14384 sgd_solver.cpp:106] Iteration 5420, lr = 0.001\n",
    "I0930 23:32:32.895139 14384 solver.cpp:228] Iteration 5440, loss = 0.000652366\n",
    "I0930 23:32:32.895139 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000652523 (* 1 = 0.000652523 loss)\n",
    "I0930 23:32:32.895139 14384 sgd_solver.cpp:106] Iteration 5440, lr = 0.001\n",
    "I0930 23:32:33.041743 14384 solver.cpp:228] Iteration 5460, loss = 0.0152879\n",
    "I0930 23:32:33.041743 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0152881 (* 1 = 0.0152881 loss)\n",
    "I0930 23:32:33.041743 14384 sgd_solver.cpp:106] Iteration 5460, lr = 0.001\n",
    "I0930 23:32:33.185344 14384 solver.cpp:228] Iteration 5480, loss = 0.00970643\n",
    "I0930 23:32:33.185844 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00970659 (* 1 = 0.00970659 loss)\n",
    "I0930 23:32:33.185844 14384 sgd_solver.cpp:106] Iteration 5480, lr = 0.001\n",
    "I0930 23:32:33.321439 14384 solver.cpp:228] Iteration 5500, loss = 0.00424803\n",
    "I0930 23:32:33.321439 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00424818 (* 1 = 0.00424818 loss)\n",
    "I0930 23:32:33.324441 14384 sgd_solver.cpp:106] Iteration 5500, lr = 0.001\n",
    "I0930 23:32:33.479050 14384 solver.cpp:228] Iteration 5520, loss = 0.00409757\n",
    "I0930 23:32:33.479050 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00409772 (* 1 = 0.00409772 loss)\n",
    "I0930 23:32:33.479050 14384 sgd_solver.cpp:106] Iteration 5520, lr = 0.001\n",
    "I0930 23:32:33.646669 14384 solver.cpp:228] Iteration 5540, loss = 0.0120396\n",
    "I0930 23:32:33.646669 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0120398 (* 1 = 0.0120398 loss)\n",
    "I0930 23:32:33.646669 14384 sgd_solver.cpp:106] Iteration 5540, lr = 0.001\n",
    "I0930 23:32:33.817790 14384 solver.cpp:228] Iteration 5560, loss = 0.00623202\n",
    "I0930 23:32:33.817790 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00623216 (* 1 = 0.00623216 loss)\n",
    "I0930 23:32:33.817790 14384 sgd_solver.cpp:106] Iteration 5560, lr = 0.001\n",
    "I0930 23:32:33.976402 14384 solver.cpp:228] Iteration 5580, loss = 0.000712418\n",
    "I0930 23:32:33.976402 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000712558 (* 1 = 0.000712558 loss)\n",
    "I0930 23:32:33.976402 14384 sgd_solver.cpp:106] Iteration 5580, lr = 0.001\n",
    "I0930 23:32:34.130511 14384 solver.cpp:228] Iteration 5600, loss = 0.000407678\n",
    "I0930 23:32:34.130511 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000407818 (* 1 = 0.000407818 loss)\n",
    "I0930 23:32:34.130511 14384 sgd_solver.cpp:106] Iteration 5600, lr = 0.001\n",
    "I0930 23:32:34.278614 14384 solver.cpp:228] Iteration 5620, loss = 0.0533167\n",
    "I0930 23:32:34.278614 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0533169 (* 1 = 0.0533169 loss)\n",
    "I0930 23:32:34.278614 14384 sgd_solver.cpp:106] Iteration 5620, lr = 0.001\n",
    "I0930 23:32:34.332152 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_5628.caffemodel\n",
    "I0930 23:32:34.348664 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_5628.solverstate\n",
    "I0930 23:32:34.355168 14384 solver.cpp:337] Iteration 5628, Testing net (#0)\n",
    "I0930 23:32:39.941931 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:32:40.483811 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9914\n",
    "I0930 23:32:40.483811 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0278566 (* 1 = 0.0278566 loss)\n",
    "I0930 23:32:40.576377 14384 solver.cpp:228] Iteration 5640, loss = 0.00603551\n",
    "I0930 23:32:40.576377 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00603567 (* 1 = 0.00603567 loss)\n",
    "I0930 23:32:40.576377 14384 sgd_solver.cpp:106] Iteration 5640, lr = 0.001\n",
    "I0930 23:32:40.759006 14384 solver.cpp:228] Iteration 5660, loss = 0.00116685\n",
    "I0930 23:32:40.759006 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.001167 (* 1 = 0.001167 loss)\n",
    "I0930 23:32:40.759006 14384 sgd_solver.cpp:106] Iteration 5660, lr = 0.001\n",
    "I0930 23:32:40.918118 14384 solver.cpp:228] Iteration 5680, loss = 0.0194598\n",
    "I0930 23:32:40.918118 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.01946 (* 1 = 0.01946 loss)\n",
    "I0930 23:32:40.918118 14384 sgd_solver.cpp:106] Iteration 5680, lr = 0.001\n",
    "I0930 23:32:41.060220 14384 solver.cpp:228] Iteration 5700, loss = 0.00349899\n",
    "I0930 23:32:41.060220 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00349915 (* 1 = 0.00349915 loss)\n",
    "I0930 23:32:41.060220 14384 sgd_solver.cpp:106] Iteration 5700, lr = 0.001\n",
    "I0930 23:32:41.225836 14384 solver.cpp:228] Iteration 5720, loss = 0.016524\n",
    "I0930 23:32:41.225836 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0165241 (* 1 = 0.0165241 loss)\n",
    "I0930 23:32:41.225836 14384 sgd_solver.cpp:106] Iteration 5720, lr = 0.001\n",
    "I0930 23:32:41.388952 14384 solver.cpp:228] Iteration 5740, loss = 0.00175885\n",
    "I0930 23:32:41.388952 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00175901 (* 1 = 0.00175901 loss)\n",
    "I0930 23:32:41.388952 14384 sgd_solver.cpp:106] Iteration 5740, lr = 0.001\n",
    "I0930 23:32:41.569578 14384 solver.cpp:228] Iteration 5760, loss = 0.03198\n",
    "I0930 23:32:41.571079 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0319802 (* 1 = 0.0319802 loss)\n",
    "I0930 23:32:41.571079 14384 sgd_solver.cpp:106] Iteration 5760, lr = 0.001\n",
    "I0930 23:32:41.735195 14384 solver.cpp:228] Iteration 5780, loss = 0.00621616\n",
    "I0930 23:32:41.735195 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00621631 (* 1 = 0.00621631 loss)\n",
    "I0930 23:32:41.735195 14384 sgd_solver.cpp:106] Iteration 5780, lr = 0.001\n",
    "I0930 23:32:41.907819 14384 solver.cpp:228] Iteration 5800, loss = 0.0181697\n",
    "I0930 23:32:41.907819 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0181698 (* 1 = 0.0181698 loss)\n",
    "I0930 23:32:41.907819 14384 sgd_solver.cpp:106] Iteration 5800, lr = 0.001\n",
    "I0930 23:32:42.067929 14384 solver.cpp:228] Iteration 5820, loss = 0.0020336\n",
    "I0930 23:32:42.067929 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00203376 (* 1 = 0.00203376 loss)\n",
    "I0930 23:32:42.067929 14384 sgd_solver.cpp:106] Iteration 5820, lr = 0.001\n",
    "I0930 23:32:42.221037 14384 solver.cpp:228] Iteration 5840, loss = 0.00176297\n",
    "I0930 23:32:42.221037 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00176313 (* 1 = 0.00176313 loss)\n",
    "I0930 23:32:42.221037 14384 sgd_solver.cpp:106] Iteration 5840, lr = 0.001\n",
    "I0930 23:32:42.381151 14384 solver.cpp:228] Iteration 5860, loss = 0.0036354\n",
    "I0930 23:32:42.381151 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00363556 (* 1 = 0.00363556 loss)\n",
    "I0930 23:32:42.381151 14384 sgd_solver.cpp:106] Iteration 5860, lr = 0.001\n",
    "I0930 23:32:42.525254 14384 solver.cpp:228] Iteration 5880, loss = 0.026578\n",
    "I0930 23:32:42.525254 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0265782 (* 1 = 0.0265782 loss)\n",
    "I0930 23:32:42.525254 14384 sgd_solver.cpp:106] Iteration 5880, lr = 0.001\n",
    "I0930 23:32:42.683364 14384 solver.cpp:228] Iteration 5900, loss = 0.0100932\n",
    "I0930 23:32:42.683364 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0100933 (* 1 = 0.0100933 loss)\n",
    "I0930 23:32:42.683364 14384 sgd_solver.cpp:106] Iteration 5900, lr = 0.001\n",
    "I0930 23:32:42.817458 14384 solver.cpp:228] Iteration 5920, loss = 0.000479612\n",
    "I0930 23:32:42.817458 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000479775 (* 1 = 0.000479775 loss)\n",
    "I0930 23:32:42.817458 14384 sgd_solver.cpp:106] Iteration 5920, lr = 0.001\n",
    "I0930 23:32:42.971068 14384 solver.cpp:228] Iteration 5940, loss = 0.0102877\n",
    "I0930 23:32:42.971068 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0102879 (* 1 = 0.0102879 loss)\n",
    "I0930 23:32:42.971068 14384 sgd_solver.cpp:106] Iteration 5940, lr = 0.001\n",
    "I0930 23:32:43.109664 14384 solver.cpp:228] Iteration 5960, loss = 0.0361364\n",
    "I0930 23:32:43.110165 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0361366 (* 1 = 0.0361366 loss)\n",
    "I0930 23:32:43.110165 14384 sgd_solver.cpp:106] Iteration 5960, lr = 0.001\n",
    "I0930 23:32:43.257269 14384 solver.cpp:228] Iteration 5980, loss = 0.00910697\n",
    "I0930 23:32:43.257269 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00910713 (* 1 = 0.00910713 loss)\n",
    "I0930 23:32:43.257269 14384 sgd_solver.cpp:106] Iteration 5980, lr = 0.001\n",
    "I0930 23:32:43.418884 14384 solver.cpp:228] Iteration 6000, loss = 0.00373918\n",
    "I0930 23:32:43.418884 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00373934 (* 1 = 0.00373934 loss)\n",
    "I0930 23:32:43.419384 14384 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001\n",
    "I0930 23:32:43.576494 14384 solver.cpp:228] Iteration 6020, loss = 0.00575199\n",
    "I0930 23:32:43.576494 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00575215 (* 1 = 0.00575215 loss)\n",
    "I0930 23:32:43.576494 14384 sgd_solver.cpp:106] Iteration 6020, lr = 0.0001\n",
    "I0930 23:32:43.732604 14384 solver.cpp:228] Iteration 6040, loss = 0.134451\n",
    "I0930 23:32:43.732604 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.134451 (* 1 = 0.134451 loss)\n",
    "I0930 23:32:43.732604 14384 sgd_solver.cpp:106] Iteration 6040, lr = 0.0001\n",
    "I0930 23:32:43.879709 14384 solver.cpp:228] Iteration 6060, loss = 0.00839718\n",
    "I0930 23:32:43.880208 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00839734 (* 1 = 0.00839734 loss)\n",
    "I0930 23:32:43.880208 14384 sgd_solver.cpp:106] Iteration 6060, lr = 0.0001\n",
    "I0930 23:32:44.041822 14384 solver.cpp:228] Iteration 6080, loss = 0.00497807\n",
    "I0930 23:32:44.041822 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00497823 (* 1 = 0.00497823 loss)\n",
    "I0930 23:32:44.041822 14384 sgd_solver.cpp:106] Iteration 6080, lr = 0.0001\n",
    "I0930 23:32:44.192428 14384 solver.cpp:228] Iteration 6100, loss = 0.00134887\n",
    "I0930 23:32:44.192428 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00134902 (* 1 = 0.00134902 loss)\n",
    "I0930 23:32:44.192428 14384 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001\n",
    "I0930 23:32:44.327524 14384 solver.cpp:228] Iteration 6120, loss = 0.00454631\n",
    "I0930 23:32:44.327524 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00454646 (* 1 = 0.00454646 loss)\n",
    "I0930 23:32:44.327524 14384 sgd_solver.cpp:106] Iteration 6120, lr = 0.0001\n",
    "I0930 23:32:44.459617 14384 solver.cpp:228] Iteration 6140, loss = 0.000348079\n",
    "I0930 23:32:44.459617 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000348224 (* 1 = 0.000348224 loss)\n",
    "I0930 23:32:44.459617 14384 sgd_solver.cpp:106] Iteration 6140, lr = 0.0001\n",
    "I0930 23:32:44.612224 14384 solver.cpp:228] Iteration 6160, loss = 0.00048189\n",
    "I0930 23:32:44.612224 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000482035 (* 1 = 0.000482035 loss)\n",
    "I0930 23:32:44.612224 14384 sgd_solver.cpp:106] Iteration 6160, lr = 0.0001\n",
    "I0930 23:32:44.763831 14384 solver.cpp:228] Iteration 6180, loss = 0.00192185\n",
    "I0930 23:32:44.764333 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00192198 (* 1 = 0.00192198 loss)\n",
    "I0930 23:32:44.764333 14384 sgd_solver.cpp:106] Iteration 6180, lr = 0.0001\n",
    "I0930 23:32:44.931951 14384 solver.cpp:228] Iteration 6200, loss = 0.00236248\n",
    "I0930 23:32:44.931951 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0023626 (* 1 = 0.0023626 loss)\n",
    "I0930 23:32:44.931951 14384 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001\n",
    "I0930 23:32:45.068547 14384 solver.cpp:228] Iteration 6220, loss = 0.0034131\n",
    "I0930 23:32:45.068547 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00341323 (* 1 = 0.00341323 loss)\n",
    "I0930 23:32:45.068547 14384 sgd_solver.cpp:106] Iteration 6220, lr = 0.0001\n",
    "I0930 23:32:45.206645 14384 solver.cpp:228] Iteration 6240, loss = 0.0786454\n",
    "I0930 23:32:45.206645 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0786455 (* 1 = 0.0786455 loss)\n",
    "I0930 23:32:45.206645 14384 sgd_solver.cpp:106] Iteration 6240, lr = 0.0001\n",
    "I0930 23:32:45.350746 14384 solver.cpp:228] Iteration 6260, loss = 0.00411938\n",
    "I0930 23:32:45.350746 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00411951 (* 1 = 0.00411951 loss)\n",
    "I0930 23:32:45.350746 14384 sgd_solver.cpp:106] Iteration 6260, lr = 0.0001\n",
    "I0930 23:32:45.497349 14384 solver.cpp:228] Iteration 6280, loss = 0.00756119\n",
    "I0930 23:32:45.497349 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00756132 (* 1 = 0.00756132 loss)\n",
    "I0930 23:32:45.497349 14384 sgd_solver.cpp:106] Iteration 6280, lr = 0.0001\n",
    "I0930 23:32:45.636948 14384 solver.cpp:228] Iteration 6300, loss = 0.00556889\n",
    "I0930 23:32:45.636948 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00556903 (* 1 = 0.00556903 loss)\n",
    "I0930 23:32:45.637449 14384 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001\n",
    "I0930 23:32:45.780550 14384 solver.cpp:228] Iteration 6320, loss = 0.0162902\n",
    "I0930 23:32:45.780550 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0162903 (* 1 = 0.0162903 loss)\n",
    "I0930 23:32:45.780550 14384 sgd_solver.cpp:106] Iteration 6320, lr = 0.0001\n",
    "I0930 23:32:45.913142 14384 solver.cpp:228] Iteration 6340, loss = 0.020808\n",
    "I0930 23:32:45.913643 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0208081 (* 1 = 0.0208081 loss)\n",
    "I0930 23:32:45.913643 14384 sgd_solver.cpp:106] Iteration 6340, lr = 0.0001\n",
    "I0930 23:32:46.052242 14384 solver.cpp:228] Iteration 6360, loss = 0.00405798\n",
    "I0930 23:32:46.052242 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00405812 (* 1 = 0.00405812 loss)\n",
    "I0930 23:32:46.052242 14384 sgd_solver.cpp:106] Iteration 6360, lr = 0.0001\n",
    "I0930 23:32:46.235370 14384 solver.cpp:228] Iteration 6380, loss = 0.0167798\n",
    "I0930 23:32:46.235872 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0167799 (* 1 = 0.0167799 loss)\n",
    "I0930 23:32:46.235872 14384 sgd_solver.cpp:106] Iteration 6380, lr = 0.0001\n",
    "I0930 23:32:46.386477 14384 solver.cpp:228] Iteration 6400, loss = 0.00440739\n",
    "I0930 23:32:46.386477 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00440753 (* 1 = 0.00440753 loss)\n",
    "I0930 23:32:46.386477 14384 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001\n",
    "I0930 23:32:46.522573 14384 solver.cpp:228] Iteration 6420, loss = 0.00671442\n",
    "I0930 23:32:46.522573 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00671455 (* 1 = 0.00671455 loss)\n",
    "I0930 23:32:46.522573 14384 sgd_solver.cpp:106] Iteration 6420, lr = 0.0001\n",
    "I0930 23:32:46.689191 14384 solver.cpp:228] Iteration 6440, loss = 0.00501356\n",
    "I0930 23:32:46.689191 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0050137 (* 1 = 0.0050137 loss)\n",
    "I0930 23:32:46.689191 14384 sgd_solver.cpp:106] Iteration 6440, lr = 0.0001\n",
    "I0930 23:32:46.857309 14384 solver.cpp:228] Iteration 6460, loss = 0.00678382\n",
    "I0930 23:32:46.857309 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00678395 (* 1 = 0.00678395 loss)\n",
    "I0930 23:32:46.857309 14384 sgd_solver.cpp:106] Iteration 6460, lr = 0.0001\n",
    "I0930 23:32:47.019424 14384 solver.cpp:228] Iteration 6480, loss = 0.0083313\n",
    "I0930 23:32:47.019424 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00833143 (* 1 = 0.00833143 loss)\n",
    "I0930 23:32:47.019424 14384 sgd_solver.cpp:106] Iteration 6480, lr = 0.0001\n",
    "I0930 23:32:47.181037 14384 solver.cpp:228] Iteration 6500, loss = 0.00610689\n",
    "I0930 23:32:47.181037 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00610703 (* 1 = 0.00610703 loss)\n",
    "I0930 23:32:47.181538 14384 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001\n",
    "I0930 23:32:47.339150 14384 solver.cpp:228] Iteration 6520, loss = 0.0108957\n",
    "I0930 23:32:47.339150 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0108958 (* 1 = 0.0108958 loss)\n",
    "I0930 23:32:47.339150 14384 sgd_solver.cpp:106] Iteration 6520, lr = 0.0001\n",
    "I0930 23:32:47.514272 14384 solver.cpp:228] Iteration 6540, loss = 0.00153229\n",
    "I0930 23:32:47.514272 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00153242 (* 1 = 0.00153242 loss)\n",
    "I0930 23:32:47.514272 14384 sgd_solver.cpp:106] Iteration 6540, lr = 0.0001\n",
    "I0930 23:32:47.680891 14384 solver.cpp:228] Iteration 6560, loss = 0.000154872\n",
    "I0930 23:32:47.680891 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000155007 (* 1 = 0.000155007 loss)\n",
    "I0930 23:32:47.680891 14384 sgd_solver.cpp:106] Iteration 6560, lr = 0.0001\n",
    "I0930 23:32:47.723420 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_6566.caffemodel\n",
    "I0930 23:32:47.742434 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_6566.solverstate\n",
    "I0930 23:32:47.748939 14384 solver.cpp:337] Iteration 6566, Testing net (#0)\n",
    "I0930 23:32:48.009623 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:32:53.679122 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9916\n",
    "I0930 23:32:53.679122 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0272481 (* 1 = 0.0272481 loss)\n",
    "I0930 23:32:53.780694 14384 solver.cpp:228] Iteration 6580, loss = 0.0069406\n",
    "I0930 23:32:53.780694 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00694073 (* 1 = 0.00694073 loss)\n",
    "I0930 23:32:53.780694 14384 sgd_solver.cpp:106] Iteration 6580, lr = 0.0001\n",
    "I0930 23:32:53.923295 14384 solver.cpp:228] Iteration 6600, loss = 0.00798852\n",
    "I0930 23:32:53.927299 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00798865 (* 1 = 0.00798865 loss)\n",
    "I0930 23:32:53.927299 14384 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001\n",
    "I0930 23:32:54.084408 14384 solver.cpp:228] Iteration 6620, loss = 0.025169\n",
    "I0930 23:32:54.084408 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0251692 (* 1 = 0.0251692 loss)\n",
    "I0930 23:32:54.084408 14384 sgd_solver.cpp:106] Iteration 6620, lr = 0.0001\n",
    "I0930 23:32:54.270540 14384 solver.cpp:228] Iteration 6640, loss = 0.0126498\n",
    "I0930 23:32:54.270540 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0126499 (* 1 = 0.0126499 loss)\n",
    "I0930 23:32:54.270540 14384 sgd_solver.cpp:106] Iteration 6640, lr = 0.0001\n",
    "I0930 23:32:54.439659 14384 solver.cpp:228] Iteration 6660, loss = 0.00550325\n",
    "I0930 23:32:54.440160 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00550338 (* 1 = 0.00550338 loss)\n",
    "I0930 23:32:54.440160 14384 sgd_solver.cpp:106] Iteration 6660, lr = 0.0001\n",
    "I0930 23:32:54.596269 14384 solver.cpp:228] Iteration 6680, loss = 0.00303157\n",
    "I0930 23:32:54.596269 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0030317 (* 1 = 0.0030317 loss)\n",
    "I0930 23:32:54.596269 14384 sgd_solver.cpp:106] Iteration 6680, lr = 0.0001\n",
    "I0930 23:32:54.749377 14384 solver.cpp:228] Iteration 6700, loss = 0.0151758\n",
    "I0930 23:32:54.749377 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.015176 (* 1 = 0.015176 loss)\n",
    "I0930 23:32:54.749377 14384 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001\n",
    "I0930 23:32:54.942513 14384 solver.cpp:228] Iteration 6720, loss = 0.00284973\n",
    "I0930 23:32:54.942513 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00284986 (* 1 = 0.00284986 loss)\n",
    "I0930 23:32:54.942513 14384 sgd_solver.cpp:106] Iteration 6720, lr = 0.0001\n",
    "I0930 23:32:55.128645 14384 solver.cpp:228] Iteration 6740, loss = 0.00134059\n",
    "I0930 23:32:55.128645 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00134072 (* 1 = 0.00134072 loss)\n",
    "I0930 23:32:55.128645 14384 sgd_solver.cpp:106] Iteration 6740, lr = 0.0001\n",
    "I0930 23:32:55.280752 14384 solver.cpp:228] Iteration 6760, loss = 0.0031977\n",
    "I0930 23:32:55.280752 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00319782 (* 1 = 0.00319782 loss)\n",
    "I0930 23:32:55.280752 14384 sgd_solver.cpp:106] Iteration 6760, lr = 0.0001\n",
    "I0930 23:32:55.427356 14384 solver.cpp:228] Iteration 6780, loss = 0.0128027\n",
    "I0930 23:32:55.427356 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0128029 (* 1 = 0.0128029 loss)\n",
    "I0930 23:32:55.427856 14384 sgd_solver.cpp:106] Iteration 6780, lr = 0.0001\n",
    "I0930 23:32:55.575460 14384 solver.cpp:228] Iteration 6800, loss = 0.00153521\n",
    "I0930 23:32:55.575460 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00153533 (* 1 = 0.00153533 loss)\n",
    "I0930 23:32:55.575460 14384 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001\n",
    "I0930 23:32:55.738075 14384 solver.cpp:228] Iteration 6820, loss = 0.00135416\n",
    "I0930 23:32:55.738075 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00135428 (* 1 = 0.00135428 loss)\n",
    "I0930 23:32:55.738075 14384 sgd_solver.cpp:106] Iteration 6820, lr = 0.0001\n",
    "I0930 23:32:55.885680 14384 solver.cpp:228] Iteration 6840, loss = 0.0249013\n",
    "I0930 23:32:55.885680 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0249015 (* 1 = 0.0249015 loss)\n",
    "I0930 23:32:55.885680 14384 sgd_solver.cpp:106] Iteration 6840, lr = 0.0001\n",
    "I0930 23:32:56.037787 14384 solver.cpp:228] Iteration 6860, loss = 0.00299641\n",
    "I0930 23:32:56.037787 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00299654 (* 1 = 0.00299654 loss)\n",
    "I0930 23:32:56.037787 14384 sgd_solver.cpp:106] Iteration 6860, lr = 0.0001\n",
    "I0930 23:32:56.192896 14384 solver.cpp:228] Iteration 6880, loss = 0.0478712\n",
    "I0930 23:32:56.192896 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0478714 (* 1 = 0.0478714 loss)\n",
    "I0930 23:32:56.192896 14384 sgd_solver.cpp:106] Iteration 6880, lr = 0.0001\n",
    "I0930 23:32:56.343001 14384 solver.cpp:228] Iteration 6900, loss = 0.00791991\n",
    "I0930 23:32:56.344002 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00792004 (* 1 = 0.00792004 loss)\n",
    "I0930 23:32:56.344002 14384 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001\n",
    "I0930 23:32:56.490105 14384 solver.cpp:228] Iteration 6920, loss = 0.00292191\n",
    "I0930 23:32:56.490105 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00292203 (* 1 = 0.00292203 loss)\n",
    "I0930 23:32:56.490105 14384 sgd_solver.cpp:106] Iteration 6920, lr = 0.0001\n",
    "I0930 23:32:56.674237 14384 solver.cpp:228] Iteration 6940, loss = 0.012289\n",
    "I0930 23:32:56.674237 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0122891 (* 1 = 0.0122891 loss)\n",
    "I0930 23:32:56.674237 14384 sgd_solver.cpp:106] Iteration 6940, lr = 0.0001\n",
    "I0930 23:32:56.851861 14384 solver.cpp:228] Iteration 6960, loss = 0.0184578\n",
    "I0930 23:32:56.851861 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0184579 (* 1 = 0.0184579 loss)\n",
    "I0930 23:32:56.851861 14384 sgd_solver.cpp:106] Iteration 6960, lr = 0.0001\n",
    "I0930 23:32:57.013975 14384 solver.cpp:228] Iteration 6980, loss = 0.0369993\n",
    "I0930 23:32:57.014475 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0369995 (* 1 = 0.0369995 loss)\n",
    "I0930 23:32:57.014475 14384 sgd_solver.cpp:106] Iteration 6980, lr = 0.0001\n",
    "I0930 23:32:57.200106 14384 solver.cpp:228] Iteration 7000, loss = 0.00446511\n",
    "I0930 23:32:57.200106 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00446524 (* 1 = 0.00446524 loss)\n",
    "I0930 23:32:57.200608 14384 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001\n",
    "I0930 23:32:57.382235 14384 solver.cpp:228] Iteration 7020, loss = 0.00473407\n",
    "I0930 23:32:57.382235 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00473419 (* 1 = 0.00473419 loss)\n",
    "I0930 23:32:57.382735 14384 sgd_solver.cpp:106] Iteration 7020, lr = 0.0001\n",
    "I0930 23:32:57.554857 14384 solver.cpp:228] Iteration 7040, loss = 0.00310197\n",
    "I0930 23:32:57.555357 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00310209 (* 1 = 0.00310209 loss)\n",
    "I0930 23:32:57.555357 14384 sgd_solver.cpp:106] Iteration 7040, lr = 0.0001\n",
    "I0930 23:32:57.709466 14384 solver.cpp:228] Iteration 7060, loss = 0.0189087\n",
    "I0930 23:32:57.709466 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0189088 (* 1 = 0.0189088 loss)\n",
    "I0930 23:32:57.709466 14384 sgd_solver.cpp:106] Iteration 7060, lr = 0.0001\n",
    "I0930 23:32:57.871580 14384 solver.cpp:228] Iteration 7080, loss = 0.0102029\n",
    "I0930 23:32:57.872081 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0102031 (* 1 = 0.0102031 loss)\n",
    "I0930 23:32:57.872081 14384 sgd_solver.cpp:106] Iteration 7080, lr = 0.0001\n",
    "I0930 23:32:58.106746 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:32:58.113250 14384 solver.cpp:228] Iteration 7100, loss = 0.0898388\n",
    "I0930 23:32:58.113250 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0898389 (* 1 = 0.0898389 loss)\n",
    "I0930 23:32:58.113250 14384 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001\n",
    "I0930 23:32:58.255352 14384 solver.cpp:228] Iteration 7120, loss = 0.0110952\n",
    "I0930 23:32:58.255352 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0110953 (* 1 = 0.0110953 loss)\n",
    "I0930 23:32:58.255352 14384 sgd_solver.cpp:106] Iteration 7120, lr = 0.0001\n",
    "I0930 23:32:58.416965 14384 solver.cpp:228] Iteration 7140, loss = 0.000813457\n",
    "I0930 23:32:58.416965 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00081358 (* 1 = 0.00081358 loss)\n",
    "I0930 23:32:58.416965 14384 sgd_solver.cpp:106] Iteration 7140, lr = 0.0001\n",
    "I0930 23:32:58.564569 14384 solver.cpp:228] Iteration 7160, loss = 0.00603886\n",
    "I0930 23:32:58.564569 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00603898 (* 1 = 0.00603898 loss)\n",
    "I0930 23:32:58.564569 14384 sgd_solver.cpp:106] Iteration 7160, lr = 0.0001\n",
    "I0930 23:32:58.715198 14384 solver.cpp:228] Iteration 7180, loss = 0.00430176\n",
    "I0930 23:32:58.715198 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00430187 (* 1 = 0.00430187 loss)\n",
    "I0930 23:32:58.715698 14384 sgd_solver.cpp:106] Iteration 7180, lr = 0.0001\n",
    "I0930 23:32:58.861801 14384 solver.cpp:228] Iteration 7200, loss = 0.00347864\n",
    "I0930 23:32:58.861801 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00347875 (* 1 = 0.00347875 loss)\n",
    "I0930 23:32:58.861801 14384 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001\n",
    "I0930 23:32:59.053442 14384 solver.cpp:228] Iteration 7220, loss = 0.00857304\n",
    "I0930 23:32:59.053442 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00857315 (* 1 = 0.00857315 loss)\n",
    "I0930 23:32:59.053442 14384 sgd_solver.cpp:106] Iteration 7220, lr = 0.0001\n",
    "I0930 23:32:59.252578 14384 solver.cpp:228] Iteration 7240, loss = 0.00239668\n",
    "I0930 23:32:59.252578 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00239679 (* 1 = 0.00239679 loss)\n",
    "I0930 23:32:59.252578 14384 sgd_solver.cpp:106] Iteration 7240, lr = 0.0001\n",
    "I0930 23:32:59.431203 14384 solver.cpp:228] Iteration 7260, loss = 0.00119152\n",
    "I0930 23:32:59.431203 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00119162 (* 1 = 0.00119162 loss)\n",
    "I0930 23:32:59.431704 14384 sgd_solver.cpp:106] Iteration 7260, lr = 0.0001\n",
    "I0930 23:32:59.582810 14384 solver.cpp:228] Iteration 7280, loss = 0.011704\n",
    "I0930 23:32:59.582810 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0117041 (* 1 = 0.0117041 loss)\n",
    "I0930 23:32:59.582810 14384 sgd_solver.cpp:106] Iteration 7280, lr = 0.0001\n",
    "I0930 23:32:59.743923 14384 solver.cpp:228] Iteration 7300, loss = 0.0234169\n",
    "I0930 23:32:59.743923 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.023417 (* 1 = 0.023417 loss)\n",
    "I0930 23:32:59.744423 14384 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001\n",
    "I0930 23:32:59.917045 14384 solver.cpp:228] Iteration 7320, loss = 0.00461629\n",
    "I0930 23:32:59.917045 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0046164 (* 1 = 0.0046164 loss)\n",
    "I0930 23:32:59.917045 14384 sgd_solver.cpp:106] Iteration 7320, lr = 0.0001\n",
    "I0930 23:33:00.070153 14384 solver.cpp:228] Iteration 7340, loss = 0.000946251\n",
    "I0930 23:33:00.070153 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000946359 (* 1 = 0.000946359 loss)\n",
    "I0930 23:33:00.070153 14384 sgd_solver.cpp:106] Iteration 7340, lr = 0.0001\n",
    "I0930 23:33:00.207751 14384 solver.cpp:228] Iteration 7360, loss = 0.00160383\n",
    "I0930 23:33:00.207751 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00160394 (* 1 = 0.00160394 loss)\n",
    "I0930 23:33:00.207751 14384 sgd_solver.cpp:106] Iteration 7360, lr = 0.0001\n",
    "I0930 23:33:00.355356 14384 solver.cpp:228] Iteration 7380, loss = 0.00096278\n",
    "I0930 23:33:00.355356 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000962892 (* 1 = 0.000962892 loss)\n",
    "I0930 23:33:00.355356 14384 sgd_solver.cpp:106] Iteration 7380, lr = 0.0001\n",
    "I0930 23:33:00.545490 14384 solver.cpp:228] Iteration 7400, loss = 0.0129073\n",
    "I0930 23:33:00.545989 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0129074 (* 1 = 0.0129074 loss)\n",
    "I0930 23:33:00.545989 14384 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001\n",
    "I0930 23:33:00.732621 14384 solver.cpp:228] Iteration 7420, loss = 0.00948204\n",
    "I0930 23:33:00.732621 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00948215 (* 1 = 0.00948215 loss)\n",
    "I0930 23:33:00.732621 14384 sgd_solver.cpp:106] Iteration 7420, lr = 0.0001\n",
    "I0930 23:33:00.893234 14384 solver.cpp:228] Iteration 7440, loss = 0.00481749\n",
    "I0930 23:33:00.893234 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0048176 (* 1 = 0.0048176 loss)\n",
    "I0930 23:33:00.893234 14384 sgd_solver.cpp:106] Iteration 7440, lr = 0.0001\n",
    "I0930 23:33:01.050345 14384 solver.cpp:228] Iteration 7460, loss = 0.0382296\n",
    "I0930 23:33:01.050345 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0382297 (* 1 = 0.0382297 loss)\n",
    "I0930 23:33:01.050345 14384 sgd_solver.cpp:106] Iteration 7460, lr = 0.0001\n",
    "I0930 23:33:01.221467 14384 solver.cpp:228] Iteration 7480, loss = 9.62176e-005\n",
    "I0930 23:33:01.221467 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 9.63211e-005 (* 1 = 9.63211e-005 loss)\n",
    "I0930 23:33:01.226469 14384 sgd_solver.cpp:106] Iteration 7480, lr = 0.0001\n",
    "I0930 23:33:01.357062 14384 solver.cpp:228] Iteration 7500, loss = 0.00343116\n",
    "I0930 23:33:01.357062 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00343126 (* 1 = 0.00343126 loss)\n",
    "I0930 23:33:01.357062 14384 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001\n",
    "I0930 23:33:01.376576 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_7504.caffemodel\n",
    "I0930 23:33:01.392587 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_7504.solverstate\n",
    "I0930 23:33:01.397089 14384 solver.cpp:337] Iteration 7504, Testing net (#0)\n",
    "I0930 23:33:07.304757 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9919\n",
    "I0930 23:33:07.304757 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0271032 (* 1 = 0.0271032 loss)\n",
    "I0930 23:33:07.421841 14384 solver.cpp:228] Iteration 7520, loss = 0.0042644\n",
    "I0930 23:33:07.421841 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0042645 (* 1 = 0.0042645 loss)\n",
    "I0930 23:33:07.421841 14384 sgd_solver.cpp:106] Iteration 7520, lr = 0.0001\n",
    "I0930 23:33:07.606971 14384 solver.cpp:228] Iteration 7540, loss = 0.00341078\n",
    "I0930 23:33:07.606971 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00341088 (* 1 = 0.00341088 loss)\n",
    "I0930 23:33:07.606971 14384 sgd_solver.cpp:106] Iteration 7540, lr = 0.0001\n",
    "I0930 23:33:07.799108 14384 solver.cpp:228] Iteration 7560, loss = 0.000942549\n",
    "I0930 23:33:07.799108 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000942653 (* 1 = 0.000942653 loss)\n",
    "I0930 23:33:07.799108 14384 sgd_solver.cpp:106] Iteration 7560, lr = 0.0001\n",
    "I0930 23:33:07.980736 14384 solver.cpp:228] Iteration 7580, loss = 0.00789597\n",
    "I0930 23:33:07.980736 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00789607 (* 1 = 0.00789607 loss)\n",
    "I0930 23:33:07.980736 14384 sgd_solver.cpp:106] Iteration 7580, lr = 0.0001\n",
    "I0930 23:33:08.147852 14384 solver.cpp:228] Iteration 7600, loss = 0.0039885\n",
    "I0930 23:33:08.147852 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00398861 (* 1 = 0.00398861 loss)\n",
    "I0930 23:33:08.147852 14384 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001\n",
    "I0930 23:33:08.231412 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:33:08.315471 14384 solver.cpp:228] Iteration 7620, loss = 0.00456464\n",
    "I0930 23:33:08.315471 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00456475 (* 1 = 0.00456475 loss)\n",
    "I0930 23:33:08.315471 14384 sgd_solver.cpp:106] Iteration 7620, lr = 0.0001\n",
    "I0930 23:33:08.471081 14384 solver.cpp:228] Iteration 7640, loss = 0.00367297\n",
    "I0930 23:33:08.471081 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00367307 (* 1 = 0.00367307 loss)\n",
    "I0930 23:33:08.471081 14384 sgd_solver.cpp:106] Iteration 7640, lr = 0.0001\n",
    "I0930 23:33:08.631695 14384 solver.cpp:228] Iteration 7660, loss = 0.00682276\n",
    "I0930 23:33:08.631695 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00682286 (* 1 = 0.00682286 loss)\n",
    "I0930 23:33:08.631695 14384 sgd_solver.cpp:106] Iteration 7660, lr = 0.0001\n",
    "I0930 23:33:08.782801 14384 solver.cpp:228] Iteration 7680, loss = 0.00120538\n",
    "I0930 23:33:08.782801 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00120548 (* 1 = 0.00120548 loss)\n",
    "I0930 23:33:08.782801 14384 sgd_solver.cpp:106] Iteration 7680, lr = 0.0001\n",
    "I0930 23:33:08.992449 14384 solver.cpp:228] Iteration 7700, loss = 0.0148681\n",
    "I0930 23:33:08.992449 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0148682 (* 1 = 0.0148682 loss)\n",
    "I0930 23:33:08.992449 14384 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001\n",
    "I0930 23:33:09.172075 14384 solver.cpp:228] Iteration 7720, loss = 0.00408301\n",
    "I0930 23:33:09.172075 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00408311 (* 1 = 0.00408311 loss)\n",
    "I0930 23:33:09.172075 14384 sgd_solver.cpp:106] Iteration 7720, lr = 0.0001\n",
    "I0930 23:33:09.337693 14384 solver.cpp:228] Iteration 7740, loss = 0.00323055\n",
    "I0930 23:33:09.338695 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00323065 (* 1 = 0.00323065 loss)\n",
    "I0930 23:33:09.338695 14384 sgd_solver.cpp:106] Iteration 7740, lr = 0.0001\n",
    "I0930 23:33:09.493803 14384 solver.cpp:228] Iteration 7760, loss = 0.0441721\n",
    "I0930 23:33:09.493803 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0441722 (* 1 = 0.0441722 loss)\n",
    "I0930 23:33:09.493803 14384 sgd_solver.cpp:106] Iteration 7760, lr = 0.0001\n",
    "I0930 23:33:09.659420 14384 solver.cpp:228] Iteration 7780, loss = 0.00465959\n",
    "I0930 23:33:09.659420 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00465969 (* 1 = 0.00465969 loss)\n",
    "I0930 23:33:09.659420 14384 sgd_solver.cpp:106] Iteration 7780, lr = 0.0001\n",
    "I0930 23:33:09.801519 14384 solver.cpp:228] Iteration 7800, loss = 0.00750326\n",
    "I0930 23:33:09.801519 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00750337 (* 1 = 0.00750337 loss)\n",
    "I0930 23:33:09.801519 14384 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001\n",
    "I0930 23:33:09.950625 14384 solver.cpp:228] Iteration 7820, loss = 0.000865005\n",
    "I0930 23:33:09.950625 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000865111 (* 1 = 0.000865111 loss)\n",
    "I0930 23:33:09.950625 14384 sgd_solver.cpp:106] Iteration 7820, lr = 0.0001\n",
    "I0930 23:33:10.112740 14384 solver.cpp:228] Iteration 7840, loss = 0.00321916\n",
    "I0930 23:33:10.112740 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00321926 (* 1 = 0.00321926 loss)\n",
    "I0930 23:33:10.112740 14384 sgd_solver.cpp:106] Iteration 7840, lr = 0.0001\n",
    "I0930 23:33:10.268350 14384 solver.cpp:228] Iteration 7860, loss = 0.0060438\n",
    "I0930 23:33:10.268350 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0060439 (* 1 = 0.0060439 loss)\n",
    "I0930 23:33:10.268350 14384 sgd_solver.cpp:106] Iteration 7860, lr = 0.0001\n",
    "I0930 23:33:10.409449 14384 solver.cpp:228] Iteration 7880, loss = 0.000342282\n",
    "I0930 23:33:10.409449 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000342386 (* 1 = 0.000342386 loss)\n",
    "I0930 23:33:10.409449 14384 sgd_solver.cpp:106] Iteration 7880, lr = 0.0001\n",
    "I0930 23:33:10.548547 14384 solver.cpp:228] Iteration 7900, loss = 0.00530159\n",
    "I0930 23:33:10.548547 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0053017 (* 1 = 0.0053017 loss)\n",
    "I0930 23:33:10.548547 14384 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001\n",
    "I0930 23:33:10.718667 14384 solver.cpp:228] Iteration 7920, loss = 0.0231686\n",
    "I0930 23:33:10.718667 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0231687 (* 1 = 0.0231687 loss)\n",
    "I0930 23:33:10.718667 14384 sgd_solver.cpp:106] Iteration 7920, lr = 0.0001\n",
    "I0930 23:33:10.878780 14384 solver.cpp:228] Iteration 7940, loss = 0.0189283\n",
    "I0930 23:33:10.878780 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0189284 (* 1 = 0.0189284 loss)\n",
    "I0930 23:33:10.879281 14384 sgd_solver.cpp:106] Iteration 7940, lr = 0.0001\n",
    "I0930 23:33:11.027895 14384 solver.cpp:228] Iteration 7960, loss = 0.00707721\n",
    "I0930 23:33:11.027895 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00707732 (* 1 = 0.00707732 loss)\n",
    "I0930 23:33:11.027895 14384 sgd_solver.cpp:106] Iteration 7960, lr = 0.0001\n",
    "I0930 23:33:11.190510 14384 solver.cpp:228] Iteration 7980, loss = 0.0131147\n",
    "I0930 23:33:11.190510 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0131148 (* 1 = 0.0131148 loss)\n",
    "I0930 23:33:11.190510 14384 sgd_solver.cpp:106] Iteration 7980, lr = 0.0001\n",
    "I0930 23:33:11.339617 14384 solver.cpp:228] Iteration 8000, loss = 0.00453445\n",
    "I0930 23:33:11.339617 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00453456 (* 1 = 0.00453456 loss)\n",
    "I0930 23:33:11.339617 14384 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001\n",
    "I0930 23:33:11.480216 14384 solver.cpp:228] Iteration 8020, loss = 0.00692502\n",
    "I0930 23:33:11.480216 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00692513 (* 1 = 0.00692513 loss)\n",
    "I0930 23:33:11.480216 14384 sgd_solver.cpp:106] Iteration 8020, lr = 0.0001\n",
    "I0930 23:33:11.627820 14384 solver.cpp:228] Iteration 8040, loss = 0.00381808\n",
    "I0930 23:33:11.627820 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00381819 (* 1 = 0.00381819 loss)\n",
    "I0930 23:33:11.627820 14384 sgd_solver.cpp:106] Iteration 8040, lr = 0.0001\n",
    "I0930 23:33:11.795439 14384 solver.cpp:228] Iteration 8060, loss = 0.00346489\n",
    "I0930 23:33:11.795439 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00346502 (* 1 = 0.00346502 loss)\n",
    "I0930 23:33:11.795439 14384 sgd_solver.cpp:106] Iteration 8060, lr = 0.0001\n",
    "I0930 23:33:11.965558 14384 solver.cpp:228] Iteration 8080, loss = 0.00960376\n",
    "I0930 23:33:11.966058 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00960388 (* 1 = 0.00960388 loss)\n",
    "I0930 23:33:11.966058 14384 sgd_solver.cpp:106] Iteration 8080, lr = 0.0001\n",
    "I0930 23:33:12.125670 14384 solver.cpp:228] Iteration 8100, loss = 0.0261803\n",
    "I0930 23:33:12.125670 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0261805 (* 1 = 0.0261805 loss)\n",
    "I0930 23:33:12.125670 14384 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001\n",
    "I0930 23:33:12.274776 14384 solver.cpp:228] Iteration 8120, loss = 0.0100344\n",
    "I0930 23:33:12.274776 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0100345 (* 1 = 0.0100345 loss)\n",
    "I0930 23:33:12.274776 14384 sgd_solver.cpp:106] Iteration 8120, lr = 0.0001\n",
    "I0930 23:33:12.409370 14384 solver.cpp:228] Iteration 8140, loss = 0.0091591\n",
    "I0930 23:33:12.409370 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00915922 (* 1 = 0.00915922 loss)\n",
    "I0930 23:33:12.409370 14384 sgd_solver.cpp:106] Iteration 8140, lr = 0.0001\n",
    "I0930 23:33:12.570484 14384 solver.cpp:228] Iteration 8160, loss = 0.000912341\n",
    "I0930 23:33:12.570484 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000912471 (* 1 = 0.000912471 loss)\n",
    "I0930 23:33:12.570484 14384 sgd_solver.cpp:106] Iteration 8160, lr = 0.0001\n",
    "I0930 23:33:12.731597 14384 solver.cpp:228] Iteration 8180, loss = 0.0138715\n",
    "I0930 23:33:12.731597 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0138716 (* 1 = 0.0138716 loss)\n",
    "I0930 23:33:12.731597 14384 sgd_solver.cpp:106] Iteration 8180, lr = 0.0001\n",
    "I0930 23:33:12.908723 14384 solver.cpp:228] Iteration 8200, loss = 0.0179051\n",
    "I0930 23:33:12.908723 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0179052 (* 1 = 0.0179052 loss)\n",
    "I0930 23:33:12.908723 14384 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001\n",
    "I0930 23:33:13.101359 14384 solver.cpp:228] Iteration 8220, loss = 0.0111841\n",
    "I0930 23:33:13.101359 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0111843 (* 1 = 0.0111843 loss)\n",
    "I0930 23:33:13.101861 14384 sgd_solver.cpp:106] Iteration 8220, lr = 0.0001\n",
    "I0930 23:33:13.276482 14384 solver.cpp:228] Iteration 8240, loss = 0.0188453\n",
    "I0930 23:33:13.276482 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0188454 (* 1 = 0.0188454 loss)\n",
    "I0930 23:33:13.276482 14384 sgd_solver.cpp:106] Iteration 8240, lr = 0.0001\n",
    "I0930 23:33:13.426087 14384 solver.cpp:228] Iteration 8260, loss = 0.0015152\n",
    "I0930 23:33:13.426087 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00151533 (* 1 = 0.00151533 loss)\n",
    "I0930 23:33:13.426087 14384 sgd_solver.cpp:106] Iteration 8260, lr = 0.0001\n",
    "I0930 23:33:13.589203 14384 solver.cpp:228] Iteration 8280, loss = 0.0142967\n",
    "I0930 23:33:13.589704 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0142969 (* 1 = 0.0142969 loss)\n",
    "I0930 23:33:13.589704 14384 sgd_solver.cpp:106] Iteration 8280, lr = 0.0001\n",
    "I0930 23:33:13.751818 14384 solver.cpp:228] Iteration 8300, loss = 0.0552413\n",
    "I0930 23:33:13.751818 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0552415 (* 1 = 0.0552415 loss)\n",
    "I0930 23:33:13.751818 14384 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001\n",
    "I0930 23:33:13.905926 14384 solver.cpp:228] Iteration 8320, loss = 0.000672602\n",
    "I0930 23:33:13.905926 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000672727 (* 1 = 0.000672727 loss)\n",
    "I0930 23:33:13.908428 14384 sgd_solver.cpp:106] Iteration 8320, lr = 0.0001\n",
    "I0930 23:33:14.050529 14384 solver.cpp:228] Iteration 8340, loss = 0.0198952\n",
    "I0930 23:33:14.050529 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0198954 (* 1 = 0.0198954 loss)\n",
    "I0930 23:33:14.050529 14384 sgd_solver.cpp:106] Iteration 8340, lr = 0.0001\n",
    "I0930 23:33:14.204138 14384 solver.cpp:228] Iteration 8360, loss = 0.00528119\n",
    "I0930 23:33:14.204138 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00528131 (* 1 = 0.00528131 loss)\n",
    "I0930 23:33:14.204138 14384 sgd_solver.cpp:106] Iteration 8360, lr = 0.0001\n",
    "I0930 23:33:14.365250 14384 solver.cpp:228] Iteration 8380, loss = 0.00504402\n",
    "I0930 23:33:14.365250 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00504414 (* 1 = 0.00504414 loss)\n",
    "I0930 23:33:14.365250 14384 sgd_solver.cpp:106] Iteration 8380, lr = 0.0001\n",
    "I0930 23:33:14.507853 14384 solver.cpp:228] Iteration 8400, loss = 0.0131307\n",
    "I0930 23:33:14.508352 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0131309 (* 1 = 0.0131309 loss)\n",
    "I0930 23:33:14.508352 14384 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001\n",
    "I0930 23:33:14.656456 14384 solver.cpp:228] Iteration 8420, loss = 0.000916708\n",
    "I0930 23:33:14.656456 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000916829 (* 1 = 0.000916829 loss)\n",
    "I0930 23:33:14.656456 14384 sgd_solver.cpp:106] Iteration 8420, lr = 0.0001\n",
    "I0930 23:33:14.820071 14384 solver.cpp:228] Iteration 8440, loss = 0.0154086\n",
    "I0930 23:33:14.820071 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0154087 (* 1 = 0.0154087 loss)\n",
    "I0930 23:33:14.820071 14384 sgd_solver.cpp:106] Iteration 8440, lr = 0.0001\n",
    "I0930 23:33:14.827577 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_8442.caffemodel\n",
    "I0930 23:33:14.843588 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_8442.solverstate\n",
    "I0930 23:33:14.850092 14384 solver.cpp:337] Iteration 8442, Testing net (#0)\n",
    "I0930 23:33:16.901540 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:33:20.816803 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9917\n",
    "I0930 23:33:20.816803 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0270297 (* 1 = 0.0270297 loss)\n",
    "I0930 23:33:20.950897 14384 solver.cpp:228] Iteration 8460, loss = 0.00164704\n",
    "I0930 23:33:20.950897 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00164715 (* 1 = 0.00164715 loss)\n",
    "I0930 23:33:20.950897 14384 sgd_solver.cpp:106] Iteration 8460, lr = 0.0001\n",
    "I0930 23:33:21.088996 14384 solver.cpp:228] Iteration 8480, loss = 0.0170702\n",
    "I0930 23:33:21.088996 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0170703 (* 1 = 0.0170703 loss)\n",
    "I0930 23:33:21.088996 14384 sgd_solver.cpp:106] Iteration 8480, lr = 0.0001\n",
    "I0930 23:33:21.236598 14384 solver.cpp:228] Iteration 8500, loss = 0.00680284\n",
    "I0930 23:33:21.236598 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00680296 (* 1 = 0.00680296 loss)\n",
    "I0930 23:33:21.236598 14384 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001\n",
    "I0930 23:33:21.385704 14384 solver.cpp:228] Iteration 8520, loss = 0.00515177\n",
    "I0930 23:33:21.385704 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00515189 (* 1 = 0.00515189 loss)\n",
    "I0930 23:33:21.385704 14384 sgd_solver.cpp:106] Iteration 8520, lr = 0.0001\n",
    "I0930 23:33:21.562328 14384 solver.cpp:228] Iteration 8540, loss = 0.00102915\n",
    "I0930 23:33:21.562328 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00102927 (* 1 = 0.00102927 loss)\n",
    "I0930 23:33:21.562328 14384 sgd_solver.cpp:106] Iteration 8540, lr = 0.0001\n",
    "I0930 23:33:21.727946 14384 solver.cpp:228] Iteration 8560, loss = 0.0078956\n",
    "I0930 23:33:21.727946 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00789572 (* 1 = 0.00789572 loss)\n",
    "I0930 23:33:21.727946 14384 sgd_solver.cpp:106] Iteration 8560, lr = 0.0001\n",
    "I0930 23:33:21.860541 14384 solver.cpp:228] Iteration 8580, loss = 0.000950758\n",
    "I0930 23:33:21.864042 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000950879 (* 1 = 0.000950879 loss)\n",
    "I0930 23:33:21.864042 14384 sgd_solver.cpp:106] Iteration 8580, lr = 0.0001\n",
    "I0930 23:33:22.012148 14384 solver.cpp:228] Iteration 8600, loss = 0.000642136\n",
    "I0930 23:33:22.012148 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000642257 (* 1 = 0.000642257 loss)\n",
    "I0930 23:33:22.012148 14384 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001\n",
    "I0930 23:33:22.162253 14384 solver.cpp:228] Iteration 8620, loss = 0.00453519\n",
    "I0930 23:33:22.162253 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00453531 (* 1 = 0.00453531 loss)\n",
    "I0930 23:33:22.162253 14384 sgd_solver.cpp:106] Iteration 8620, lr = 0.0001\n",
    "I0930 23:33:22.308357 14384 solver.cpp:228] Iteration 8640, loss = 0.00245779\n",
    "I0930 23:33:22.308357 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0024579 (* 1 = 0.0024579 loss)\n",
    "I0930 23:33:22.308357 14384 sgd_solver.cpp:106] Iteration 8640, lr = 0.0001\n",
    "I0930 23:33:22.464965 14384 solver.cpp:228] Iteration 8660, loss = 0.00337495\n",
    "I0930 23:33:22.464965 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00337507 (* 1 = 0.00337507 loss)\n",
    "I0930 23:33:22.464965 14384 sgd_solver.cpp:106] Iteration 8660, lr = 0.0001\n",
    "I0930 23:33:22.600561 14384 solver.cpp:228] Iteration 8680, loss = 0.00121427\n",
    "I0930 23:33:22.600561 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00121438 (* 1 = 0.00121438 loss)\n",
    "I0930 23:33:22.600561 14384 sgd_solver.cpp:106] Iteration 8680, lr = 0.0001\n",
    "I0930 23:33:22.742662 14384 solver.cpp:228] Iteration 8700, loss = 0.00164309\n",
    "I0930 23:33:22.742662 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00164319 (* 1 = 0.00164319 loss)\n",
    "I0930 23:33:22.742662 14384 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001\n",
    "I0930 23:33:22.894769 14384 solver.cpp:228] Iteration 8720, loss = 0.00324747\n",
    "I0930 23:33:22.894769 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00324758 (* 1 = 0.00324758 loss)\n",
    "I0930 23:33:22.894769 14384 sgd_solver.cpp:106] Iteration 8720, lr = 0.0001\n",
    "I0930 23:33:23.066390 14384 solver.cpp:228] Iteration 8740, loss = 0.0122509\n",
    "I0930 23:33:23.066390 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.012251 (* 1 = 0.012251 loss)\n",
    "I0930 23:33:23.066390 14384 sgd_solver.cpp:106] Iteration 8740, lr = 0.0001\n",
    "I0930 23:33:23.242514 14384 solver.cpp:228] Iteration 8760, loss = 0.021143\n",
    "I0930 23:33:23.242514 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0211431 (* 1 = 0.0211431 loss)\n",
    "I0930 23:33:23.242514 14384 sgd_solver.cpp:106] Iteration 8760, lr = 0.0001\n",
    "I0930 23:33:23.417639 14384 solver.cpp:228] Iteration 8780, loss = 0.00928108\n",
    "I0930 23:33:23.417639 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00928119 (* 1 = 0.00928119 loss)\n",
    "I0930 23:33:23.417639 14384 sgd_solver.cpp:106] Iteration 8780, lr = 0.0001\n",
    "I0930 23:33:23.593262 14384 solver.cpp:228] Iteration 8800, loss = 0.00204285\n",
    "I0930 23:33:23.593763 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00204297 (* 1 = 0.00204297 loss)\n",
    "I0930 23:33:23.593763 14384 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001\n",
    "I0930 23:33:23.755376 14384 solver.cpp:228] Iteration 8820, loss = 0.00811654\n",
    "I0930 23:33:23.755376 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00811665 (* 1 = 0.00811665 loss)\n",
    "I0930 23:33:23.755376 14384 sgd_solver.cpp:106] Iteration 8820, lr = 0.0001\n",
    "I0930 23:33:23.903481 14384 solver.cpp:228] Iteration 8840, loss = 0.0223969\n",
    "I0930 23:33:23.903481 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.022397 (* 1 = 0.022397 loss)\n",
    "I0930 23:33:23.903481 14384 sgd_solver.cpp:106] Iteration 8840, lr = 0.0001\n",
    "I0930 23:33:24.112128 14384 solver.cpp:228] Iteration 8860, loss = 0.00896416\n",
    "I0930 23:33:24.112628 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00896428 (* 1 = 0.00896428 loss)\n",
    "I0930 23:33:24.112628 14384 sgd_solver.cpp:106] Iteration 8860, lr = 0.0001\n",
    "I0930 23:33:24.343791 14384 solver.cpp:228] Iteration 8880, loss = 0.00714738\n",
    "I0930 23:33:24.348795 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0071475 (* 1 = 0.0071475 loss)\n",
    "I0930 23:33:24.348795 14384 sgd_solver.cpp:106] Iteration 8880, lr = 0.0001\n",
    "I0930 23:33:24.543431 14384 solver.cpp:228] Iteration 8900, loss = 0.00159037\n",
    "I0930 23:33:24.543431 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00159048 (* 1 = 0.00159048 loss)\n",
    "I0930 23:33:24.543431 14384 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001\n",
    "I0930 23:33:24.786604 14384 solver.cpp:228] Iteration 8920, loss = 0.00191322\n",
    "I0930 23:33:24.786604 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00191333 (* 1 = 0.00191333 loss)\n",
    "I0930 23:33:24.786604 14384 sgd_solver.cpp:106] Iteration 8920, lr = 0.0001\n",
    "I0930 23:33:24.927202 14384 solver.cpp:228] Iteration 8940, loss = 0.003345\n",
    "I0930 23:33:24.927703 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00334512 (* 1 = 0.00334512 loss)\n",
    "I0930 23:33:24.927703 14384 sgd_solver.cpp:106] Iteration 8940, lr = 0.0001\n",
    "I0930 23:33:25.065800 14384 solver.cpp:228] Iteration 8960, loss = 0.00670063\n",
    "I0930 23:33:25.065800 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00670075 (* 1 = 0.00670075 loss)\n",
    "I0930 23:33:25.065800 14384 sgd_solver.cpp:106] Iteration 8960, lr = 0.0001\n",
    "I0930 23:33:25.227414 14384 solver.cpp:228] Iteration 8980, loss = 0.0445474\n",
    "I0930 23:33:25.227915 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0445476 (* 1 = 0.0445476 loss)\n",
    "I0930 23:33:25.227915 14384 sgd_solver.cpp:106] Iteration 8980, lr = 0.0001\n",
    "I0930 23:33:25.389029 14384 solver.cpp:228] Iteration 9000, loss = 0.0173393\n",
    "I0930 23:33:25.389029 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0173394 (* 1 = 0.0173394 loss)\n",
    "I0930 23:33:25.389029 14384 sgd_solver.cpp:106] Iteration 9000, lr = 1e-005\n",
    "I0930 23:33:25.531630 14384 solver.cpp:228] Iteration 9020, loss = 0.00416184\n",
    "I0930 23:33:25.531630 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00416195 (* 1 = 0.00416195 loss)\n",
    "I0930 23:33:25.531630 14384 sgd_solver.cpp:106] Iteration 9020, lr = 1e-005\n",
    "I0930 23:33:25.687739 14384 solver.cpp:228] Iteration 9040, loss = 0.00718275\n",
    "I0930 23:33:25.687739 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00718287 (* 1 = 0.00718287 loss)\n",
    "I0930 23:33:25.687739 14384 sgd_solver.cpp:106] Iteration 9040, lr = 1e-005\n",
    "I0930 23:33:25.844350 14384 solver.cpp:228] Iteration 9060, loss = 0.00586939\n",
    "I0930 23:33:25.844350 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00586951 (* 1 = 0.00586951 loss)\n",
    "I0930 23:33:25.844350 14384 sgd_solver.cpp:106] Iteration 9060, lr = 1e-005\n",
    "I0930 23:33:26.033985 14384 solver.cpp:228] Iteration 9080, loss = 0.00668336\n",
    "I0930 23:33:26.033985 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00668348 (* 1 = 0.00668348 loss)\n",
    "I0930 23:33:26.033985 14384 sgd_solver.cpp:106] Iteration 9080, lr = 1e-005\n",
    "I0930 23:33:26.279156 14384 solver.cpp:228] Iteration 9100, loss = 0.0101339\n",
    "I0930 23:33:26.279156 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.010134 (* 1 = 0.010134 loss)\n",
    "I0930 23:33:26.279156 14384 sgd_solver.cpp:106] Iteration 9100, lr = 1e-005\n",
    "I0930 23:33:26.441771 14384 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
    "I0930 23:33:26.456781 14384 solver.cpp:228] Iteration 9120, loss = 0.00147936\n",
    "I0930 23:33:26.456781 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00147947 (* 1 = 0.00147947 loss)\n",
    "I0930 23:33:26.457283 14384 sgd_solver.cpp:106] Iteration 9120, lr = 1e-005\n",
    "I0930 23:33:26.647919 14384 solver.cpp:228] Iteration 9140, loss = 0.00350618\n",
    "I0930 23:33:26.648422 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00350629 (* 1 = 0.00350629 loss)\n",
    "I0930 23:33:26.648422 14384 sgd_solver.cpp:106] Iteration 9140, lr = 1e-005\n",
    "I0930 23:33:26.807029 14384 solver.cpp:228] Iteration 9160, loss = 0.030936\n",
    "I0930 23:33:26.807029 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.0309361 (* 1 = 0.0309361 loss)\n",
    "I0930 23:33:26.811532 14384 sgd_solver.cpp:106] Iteration 9160, lr = 1e-005\n",
    "I0930 23:33:26.967142 14384 solver.cpp:228] Iteration 9180, loss = 0.00602244\n",
    "I0930 23:33:26.967142 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00602255 (* 1 = 0.00602255 loss)\n",
    "I0930 23:33:26.967142 14384 sgd_solver.cpp:106] Iteration 9180, lr = 1e-005\n",
    "I0930 23:33:27.122751 14384 solver.cpp:228] Iteration 9200, loss = 0.00275865\n",
    "I0930 23:33:27.122751 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00275876 (* 1 = 0.00275876 loss)\n",
    "I0930 23:33:27.122751 14384 sgd_solver.cpp:106] Iteration 9200, lr = 1e-005\n",
    "I0930 23:33:27.268355 14384 solver.cpp:228] Iteration 9220, loss = 0.00316606\n",
    "I0930 23:33:27.268355 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00316617 (* 1 = 0.00316617 loss)\n",
    "I0930 23:33:27.268355 14384 sgd_solver.cpp:106] Iteration 9220, lr = 1e-005\n",
    "I0930 23:33:27.422965 14384 solver.cpp:228] Iteration 9240, loss = 0.000465948\n",
    "I0930 23:33:27.422965 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000466066 (* 1 = 0.000466066 loss)\n",
    "I0930 23:33:27.422965 14384 sgd_solver.cpp:106] Iteration 9240, lr = 1e-005\n",
    "I0930 23:33:27.574571 14384 solver.cpp:228] Iteration 9260, loss = 0.00607474\n",
    "I0930 23:33:27.574571 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00607485 (* 1 = 0.00607485 loss)\n",
    "I0930 23:33:27.574571 14384 sgd_solver.cpp:106] Iteration 9260, lr = 1e-005\n",
    "I0930 23:33:27.726177 14384 solver.cpp:228] Iteration 9280, loss = 0.0020163\n",
    "I0930 23:33:27.726177 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00201642 (* 1 = 0.00201642 loss)\n",
    "I0930 23:33:27.726177 14384 sgd_solver.cpp:106] Iteration 9280, lr = 1e-005\n",
    "I0930 23:33:27.864275 14384 solver.cpp:228] Iteration 9300, loss = 0.00595524\n",
    "I0930 23:33:27.864275 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00595535 (* 1 = 0.00595535 loss)\n",
    "I0930 23:33:27.864275 14384 sgd_solver.cpp:106] Iteration 9300, lr = 1e-005\n",
    "I0930 23:33:28.044903 14384 solver.cpp:228] Iteration 9320, loss = 0.00384556\n",
    "I0930 23:33:28.044903 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00384568 (* 1 = 0.00384568 loss)\n",
    "I0930 23:33:28.044903 14384 sgd_solver.cpp:106] Iteration 9320, lr = 1e-005\n",
    "I0930 23:33:28.193007 14384 solver.cpp:228] Iteration 9340, loss = 0.00833596\n",
    "I0930 23:33:28.193007 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.00833608 (* 1 = 0.00833608 loss)\n",
    "I0930 23:33:28.193007 14384 sgd_solver.cpp:106] Iteration 9340, lr = 1e-005\n",
    "I0930 23:33:28.348117 14384 solver.cpp:228] Iteration 9360, loss = 0.00015619\n",
    "I0930 23:33:28.348117 14384 solver.cpp:244]     Train net output #0: SoftmaxWithLoss1 = 0.000156311 (* 1 = 0.000156311 loss)\n",
    "I0930 23:33:28.348117 14384 sgd_solver.cpp:106] Iteration 9360, lr = 1e-005\n",
    "I0930 23:33:28.515734 14384 solver.cpp:454] Snapshotting to binary proto file G:/workspace/caffe/mnist/lenet_iter_9380.caffemodel\n",
    "I0930 23:33:28.532747 14384 sgd_solver.cpp:273] Snapshotting solver state to binary proto file G:/workspace/caffe/mnist/lenet_iter_9380.solverstate\n",
    "I0930 23:33:28.540251 14384 solver.cpp:317] Iteration 9380, loss = 0.00319914\n",
    "I0930 23:33:28.540251 14384 solver.cpp:337] Iteration 9380, Testing net (#0)\n",
    "I0930 23:33:34.742629 14384 solver.cpp:404]     Test net output #0: Accuracy1 = 0.9918\n",
    "I0930 23:33:34.742629 14384 solver.cpp:404]     Test net output #1: SoftmaxWithLoss1 = 0.0270079 (* 1 = 0.0270079 loss)\n",
    "I0930 23:33:34.742629 14384 solver.cpp:322] Optimization Done.\n",
    "\n",
    "Process finished with exit code 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
